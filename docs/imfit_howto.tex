\documentclass[10pt,a4paper,article]{memoir}

\usepackage[T1]{fontenc}

% Specify use of Minion Pro as the main typeface
\usepackage[lf]{MinionPro}
%\usepackage{MnSymbol}
% specify Inconsolata for tt (including verbatim environment)
%\usepackage{inconsolata}

% microtypography package -- mainly so we can firmly turn off ligatures for tt font
% (otherwise we sometimes get "--" --> en-dash, which we don't want in command-line
% and code examples!)
\usepackage[expansion=false]{microtype}
\DisableLigatures{encoding = T1, family = tt* }


% Palatino options:
% specify "sc" option to get true small caps, not scaled-down regular caps
%\usepackage[sc]{mathpazo}
% the following works find (and has slightly nicer Greek letters than mathpazo),
% but doesn't let you use true small caps:
%\usepackage{mathpple}

% Note: the following warnings may not be true anymore (2013); at least, mathpple works
% FOLLOWING DOES NOT WORK [URW Garamond NOT INSTALLED?]
%\usepackage[garamond]{mathdesign}
% FOLLOWING DOES NOT WORK [SOME METRIC FILES ARE MISSING]
%\usepackage[]{mathtime}
% FOLLOWING DOES NOT WORK [EULER FONTS NOT INSTALLED?]
%\usepackage[]{mathpple}


% current Small Caps policy: things that are 3+ characters *and* that are like
% names: thus, GNU, GCC, FITS, MINPACK; but CPU and PSF are not "names", and thus remains
% as full caps.

%\usepackage{amssymb}

\usepackage{amsmath}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{color}

%\usepackage{fancyhdr}
%\pagestyle{fancy}
%\lhead{\textsc{Imfit Howto}}
%\chead{}

\usepackage{listings}
\lstset{language=C}

% Document layout and typography
\setlength{\oddsidemargin}{1.0cm}
\setlength{\textwidth}{13.5cm}
% increase leading to 1.1 * (1.2 * type size)
%    --> 1.07 * 1.2 * 10pt = 12.8 pt
\linespread{1.07}

% Default forms for package and program names
\newcommand{\imfit}{\textbf{Imfit}}
\newcommand{\Imfit}{\textbf{Imfit}}
\newcommand{\imfitprog}{\texttt{imfit}}
\newcommand{\imfitmcmc}{\texttt{imfit-mcmc}}
\newcommand{\makeimage}{\texttt{makeimage}}
\newcommand{\Makeimage}{\texttt{Makeimage}}

% math and math-related definitions
\newcommand{\arcdeg}{\ensuremath{^{\circ}}}
\newcommand{\chisquare}{\ensuremath{\chi^{2}}}
\newcommand{\chisquaredata}{\ensuremath{\chi_{d}^{2}}}
\newcommand{\chisquaremodel}{\ensuremath{\chi_{m}^{2}}}
\newcommand{\rbar}{\ensuremath{R_{\mathrm{bar}}}}
\newcommand{\pmlr}{PMLR}

% Other stuff, including version number
\newcommand{\versionnum}{1.8.0}

\newcommand{\red}{\textcolor{red}}



\begin{document}

% Definition of title page:
\title{
  Notes for Using Imfit \\
  (Version \versionnum{})
}
\author{
  Peter Erwin\\
  MPE and USM\\
  \href{mailto:erwin@sigmaxi.net}{erwin@sigmaxi.net}
}
\date{\today}  % optional

\maketitle

\tableofcontents


\newpage

\chapter{What Is It?}

\Imfit{} is a program for fitting astronomical images -- specifically,
for fitting images of galaxies, though it could certainly be used for
fitting other sources. The user specifies a set of one or more 2D
surface-brightness functions (e.g., elliptical exponential, elliptical
S\'ersic, circular Gaussian) which will be added together in order to
generate a model image; this model image will then be matched to the
input image by adjusting the 2D function parameters via nonlinear
minimization of the total \chisquare{} (or of the total Cash or
Poisson-MLR statistics in the alternate case of Poisson statistics).

The 2D functions can be grouped into arbitrary sets sharing a common $(x,y)$
position on the image plane; this allows galaxies with off-center components
or multiple galaxies to be fit simultaneously. Parameters for the individual
functions can be held fixed or restricted to user-specified ranges. The
model image can (optionally) be convolved with a point spread
function (PSF) image to better match the input image; the PSF image can
be any square, centered image the user supplies -- e.g., an analytic 2D Gaussian
or Moffat, a \textit{Hubble Space Telescope} PSF generated by the TinyTim
program\footnote{\url{http://www.stsci.edu/software/tinytim/}} \citep{krist95}, 
or an actual stellar image. (A higher-resolution, ``oversampled'' PSF image
can also be used for one or more subsections of the full image.) 

A key part of \imfit{} is a modular, object-oriented design that allows easy
addition of new, user-specified 2D image functions. This is accomplished by
writing C++ code for a new image-function class (this can be done by copying and
modifying an existing pair of \texttt{.h/.cpp} files for one of the pre-supplied
image functions), making small modifications to two additional files to include
references to the new function, and re-compiling the program.

\Imfit{} is an open-source project; the source code is freely available
under the \textsc{gnu} Public License (\textsc{gpl}).


\bigskip

\textbf{A note on names:} The \imfit{} package consists of three programs:
\begin{itemize}
\item \imfitprog{} -- the main image-fitting program; \\
\item \imfitmcmc{} -- a program to do Markov chain Monte Carlo (MCMC) analysis; \\
\item \makeimage{} -- an auxiliary program which can be used to
generate artificial galaxy images (using the same input/output
parameter-file format that \imfitprog{} uses). \\
\end{itemize}
In this document, I use \imfit{} (in boldface) to refer to the whole
package and \imfitprog{} to specific use of the actual fitting program,
although I'm not entirely consistent about this; in most cases this
distinction should be meaningless. (I.e., in most cases you're using the
\imfitprog{} binary to fit images.)


\bigskip

\textbf{System Requirements:} \Imfit{} has been built and tested on
Intel-based MacOS X (or macOS) 10.8--10.13 (Mountain Lion, Mavericks,
Yosemite, El Capitan, Sierra, and High Sierra)\footnote{Versions 1.3 and earlier were
also built for MacOS X 10.6 and 10.7; it's unclear whether the current
version could still be compiled for those systems.} and Linux (Ubuntu)
systems. It uses standard C++ or C++11 and should work on most
Unix-style systems with a modern C++ compiler and the Standard Template
Library (e.g., \textsc{gcc} v4.8.1 or higher). It relies on three
external, open-source libraries: version 3 of the \textsc{cfitsio}
library\footnote{\url{https://heasarc.nasa.gov/fitsio/}} for
\textsc{fits} image I/O, version 3 of the \textsc{fftw} (Fastest Fourier
Transform in the West) library\footnote{\url{http://www.fftw.org/}} for
PSF convolution, and version 2.0 or higher of the \textsc{gnu}
Scientific Library
(\textsc{gsl}),\footnote{\url{https://www.gnu.org/software/gsl/}}. Some
of the fitting algorithms require the NLopt
library\footnote{\url{https://nlopt.readthedocs.io/en/latest/}}, but the
program can also be built without it.

\bigskip

\Imfit{} also includes modified versions of Craig Markwardt's
\texttt{mpfit} code (an enhanced version of the \textsc{minpack-1}
Levenberg-Marquardt least-squares fitting code); the Differential
Evolution fitting code of Rainer Storn and Kenneth Price (more
specifically, a C++ wrapper written by Lester E. Godwin); and
an implementation of the MCMC DREAM algorithm in C++ by Gabriel 
Leventhal.\footnote{\url{https://github.com/gaberoo/cdream}}



\newpage

\chapter{Getting and Installing \Imfit{}}

\section{Pre-Compiled Binaries}

Pre-built binaries for Intel-based MacOS X and Linux systems, along with
the source code, are available at
\url{https://www.mpe.mpg.de/~erwin/code/imfit/}. The pre-compiled
binaries included statically linked versions of the \textsc{cfitsio},
\textsc{fftw}, \textsc{gsl}, and NLopt libraries, so you do not need to
have those installed. (The pre-built Linux binaries \textit{do} require
that the system GNU C library be version 2.15 or more recent; try typing
\texttt{ldd --version} at the command line to find out.)

Inside the binary-install tarball, there are three binary executable
files: \imfitprog, \imfitmcmc, and \makeimage{}. Copy these to some
convenient place on your path.

\subsection{Useful Extras}

The binary-install tarball has a \texttt{docs/} subdirectory with a
copy of the \Imfit{} manual in PDF and \LaTeX{} form.

There is also an \texttt{examples/} subdirectory with sample files; see
the \texttt{README\_examples.txt} file there for simple examples of how
to use \Imfit{} with those files. (This includes the files used in the 
online tutorial.\footnote{\url{https://www.mpe.mpg.de/~erwin/code/imfit/markdown/index.html}})

If you use the bash shell, there is a tab-completion file in the
\texttt{extras/} subdirectory. Copy the file \texttt{imfit\_completions.bash}
to somewhere convenient and 
add the following to your \texttt{.profile}, \texttt{.bash\_profile}, or 
\texttt{.bashrc} file:

\begin{verbatim}
    source /path/to/imfit_completions.bash
\end{verbatim}

You should then (assuming you restart your shell, open a new terminal
window, or something similar) be able to type ``\texttt{imfit --}'', press the
TAB key a couple of times, and get a listing of the command-line flags
and options; typing part of a flag/option and then pressing TAB should
complete the command. (And similarly for \imfitmcmc{} and \makeimage{}.)



\section{Building \Imfit{} from Source: Outline}

The standard source-code distribution for \Imfit{} can be found at the
main \Imfit{} web site (see above). (The ``useful extras'' listed above
are of course included in the source-code distribution.) An expanded version of
the source code (including extra tests, notes, and auxiliary programs)
can be found at \Imfit's GitHub site:
\url{https://github.com/perwin/imfit}.

The basic outline for building \Imfit{} from source is:

\begin{enumerate}
\item Install the \textsc{cfitsio} library (version 3.0 or higher).

\item Install the \textsc{gnu} Scientific Library (\textsc{gsl}; version 2.0 or higher).

\item Install the \textsc{fftw} library (version 3.0 or higher). Note
that if you have a multi-core CPU (or multiple CPUs sharing main
memory), you should build and install the threaded version of
\textsc{fftw} as well (this will probably involve running its
``configure'' script with the \texttt{--enable-threaded} option; see
the \textsc{fftw} manual for details), since this speeds up PSF convolution
considerably. Building \textsc{fftw} with SSE2 and AVX support will
provide a $\sim 10$--20\% speedup for PSF convolutions, so that's also
recommended, though not as strongly.

\item (Optional, but strongly recommended) Install the NLopt library --
this is necessary if you wish to use the Nelder-Mead minimization
algorithm. \Imfit{} can be built without this, if for some reason
you don't have access to the NLopt library.

\item Install SCons (if needed; see below).

\item Build \imfitprog, \imfitmcmc, and \makeimage.

\item (Optional) Run test scripts \texttt{do\_imfit\_tests}, \texttt{do\_mcmc\_tests},
and \texttt{do\_makeimage\_tests}.

\end{enumerate}



\section{Building \Imfit{} from Source: Details}\label{sec:build}

Assuming that \textsc{cfitsio}, \textsc{fftw}, NLopt, and \textsc{gsl}
have already been installed on your system (steps 1--4 from the outline
in the previous section), unpack the source-code tarball
(imfit-x.x-source.tar.gz) in some convenient location. (Or, if you
prefer, use `git clone` to download the full repo from GitHub.)

\subsubsection{Building with SCons}

By default, \imfit{} uses SCons for the build process. SCons is a Python-based build system
that is somewhat easier to use and more flexible than the traditional \texttt{make}
system; it can be downloaded from \url{https://www.scons.org/} or installed via
your favorite package manager, including Python's Pip, e.g.
\begin{quote}
\texttt{\$ pip install scons}
\end{quote}

If things are simple, you should be able to build \imfit{} and the companion
program \makeimage{} with the following commands:
\begin{quote}
\texttt{\$ scons imfit} \\
\texttt{\$ scons imfit-mcmc} \\
\texttt{\$ scons makeimage}
\end{quote}
This will produce three binary executable files: \imfitprog, \imfitmcmc, and \makeimage{}. Copy
these to some convenient place on your path.

If you do not have the NLopt library installed, you will get compilation errors;
this can be dealt with by using:
\begin{quote}
\verb+$ scons --no-nlopt imfit+ \\
\verb+$ scons --no-nlopt imfit-mcmc+ \\
\verb+$ scons --no-nlopt makeimage+
\end{quote}

%Similarly, if you do not have \textsc{gsl} installed, you will get compilation errors; use the following
%commands instead (note that you cannot build \imfitmcmc{} without \textsc{gsl}):
%\begin{quote}
%\verb+$ scons --no-gsl imfit+ \\
%\verb+$ scons --no-gsl makeimage+
%\end{quote}

Various other compilation options may be useful, particularly for telling SCons where
to look for library files; these are explained in the next
subsections (note that all the SCons options can be combined on the command
line).


\subsubsection{Tests}

Finally, there are three shell scripts -- \texttt{do\_imfit\_tests},
\texttt{do\_mcmc\_tests}, and \texttt{do\_makeimage\_tests} -- which can
be run to do some very simple sanity checks (e.g., do the programs fit
some simple images correctly, are common config-file errors caught,
etc.). They make use of files and data in the \texttt{tests/}
subdirectory. 

Differences in output at the level of the least significant digit
compared to the reference files may occur when running the tests on a
Linux system; these should not be considered problems. (This sort of
thing appears to depend on subtle differences in how different compilers
and libraries handle floating-point computations and rounding.)

For the full set of tests to run, you should have Python version 2.6,
2.7, or 3.5+ installed, along with the Python libraries
numpy\footnote{\url{https://www.numpy.org}} and
astropy.\footnote{\url{https://www.astropy.org}} If these are not
available, then the parts of the tests which compare output images with
reference versions will be skipped.



\subsubsection{Telling the Compiler Where to Find Header Files and Libraries}

By default, the SConstruct file (the equivalent of a Makefile for SCons) included
in the source distribution for \imfit{}
tells SCons to look for header files in \texttt{/usr/local/include} and
library files in \texttt{/usr/local/lib}. If you have the \textsc{fftw},
\textsc{cfitsio}, \textsc{gsl}, and/or (optionally) NLopt and headers and
libraries installed somewhere else, you can tell SCons about this by
using the
\texttt{--header-path} and \texttt{--lib-path} options:
\begin{quote}
\texttt{\$ scons --header-path=/some/path ...} \\
\texttt{\$ scons --lib-path=/some/other/path ...}
\end{quote}
(note that "\texttt{...}" is meant to stand for the rest of the compilation command,
whatever that may be). This will add the specified directories to the
header and library search paths (\texttt{/usr/local/include} and \texttt{/usr/local/lib}
will still be searched as well).

Multiple paths can be specified if they are separated by colons, e.g.
\begin{quote}
\texttt{\$ scons --lib-path=/some/path:/some/other/path ...} \\
\end{quote}

%If you are using \texttt{configure + make} instead of SCons, you can specify the
%paths to the relevant header and library files via:
%\begin{quote}
%./configure CPPFLAGS=-I/the/location/include LDFLAGS=-L/the/location/lib
%\end{quote}


\subsubsection{Options: Compiling Without OpenMP Support}

By default, \imfitprog{} and \makeimage{} are compiled to take advantage
of OpenMP compiler support, which speeds up image computation (a
\textit{lot}) by splitting it up across multiple CPUs (and multiple
cores within multi-core CPUs). The code uses OpenMP 2.5 options, which
are available with versions of \textsc{gcc} 4.2 or higher. (Though since
the code also uses C++11 features, you really need \textsc{gcc} 4.8.1 or
higher.)

If your compiler
does not support OpenMP -- or you want, for whatever reason, a version
that does not include OpenMP support -- you can disable it by compiling
with the following commands:
\begin{quote}
\texttt{\$ scons --no-openmp ...}
\end{quote}


\subsubsection{Compiling on macOS}

The standard compiler tools for macOS (formerly Mac OS~X) are those
which come with Apple's Xcode, which for C and C++ are based on LLVM's
Clang. (Confusingly, the Clang-based tools include ``\texttt{gcc}'' and
``\texttt{g++}'' aliases which are wrappers around \texttt{clang} and
\texttt{clang++}. To be sure, try \texttt{gcc -v}; if you see something
like ``Apple LLVM version'', then you know it's really the Clang
compiler.)

Prior to version 9 of Xcode (introduced in late 2017), the
Apple-supplied Clang compiler did \textit{not} support OpenMP (even though
the general non-Apple version did); this meant
that compiling \imfit{} with OpenMP required a separate installation
of \textsc{gcc}. Now, there \textit{is} support for OpenMP, though
you will still need to install an additional library (see below).

\bigskip

Currently, there are two approaches for compiling \imfit{} on macOS:


\paragraph{1. Use a Separate GCC (or LLVM) Installation}

For current versions of \imfit{}, you can use a separate installation of
GCC (this should be version 4.8.1 or later), such as those available via
package managers such as Homebrew or MacPorts. (Note that Homebrew does
not \textit{replace} the pseudo-``gcc'' and ``g++'' aliases provided by
Xcode, which will still point to Apple's Clang compilers; instead, it
installs version-specific names such as ``gcc-9'' and ``g++-9''.)
Another alternative is to install a version of LLVM/Clang that
\textit{does} support OpenMP, e.g., from one of the aforementioned
package managers.

To tell SCons to use a specific compiler, use the
\texttt{--cpp} option:
\begin{quote}
\texttt{\$ scons --cpp=<C++\_COMPILER> ...}
\end{quote}



\paragraph{2. Use Apple's Clang}

As mentioned above, versions of Apple's Clang from Xcode 9 or later provide
support for OpenMP. However, this is not (quite) automatic: you still
need to install a copy of \texttt{libomp}, which is the LLVM version of
the OpenMP library. This can be done via a package manager like Homebrew
or MacPorts. For example, to install it using Homebrew, just do this:
\begin{quote}
\texttt{\$ brew install libomp}
\end{quote}

Since supporting this in \imfit{} is still a bit experimental, you need
to tell SCons to explicitly use this approach via the \texttt{--clang-openmp}
option:
\begin{quote}
\texttt{\$ scons --clang-openmp ...}
\end{quote}


\subsubsection{Options: Compiling Without FFT Multithreading}

By default, the \Imfit{} binaries are compiled to take advantage of
multi-core CPUs (and other shared-memory multiple-processor systems)
when performing PSF convolutions by using the multithreaded version of
the \textsc{fftw} library. If you do not have (or cannot build) the
multithreaded \textsc{fftw} library, you can remove multithreaded FFT
computation by compiling with the following commands:
\begin{quote}
\texttt{\$ scons --no-threading imfit} \\
\texttt{\$ scons --no-threading imfit-mcmc} \\
\texttt{\$ scons --no-threading makeimage}
\end{quote}





\newpage

\chapter{Trying It Out}

In the \texttt{examples/} directory are some sample galaxy images, masks, PSF images, and
configuration files. To give \imfit{} a quick spin (and check that it's working on your system), change to the
\texttt{examples/} directory and execute the following on the command line (assuming that
the \imfitprog{} binary is now in your path; if it isn't you can access it via
\texttt{../imfit}):
\begin{quote}
\texttt{\$ imfit ic3478rss\_256.fits \texttt{-c} config\_sersic\_ic3478\_256.dat \texttt{--}sky=130.14}
\end{quote}

This converges to a fit in a few seconds or less (e.g., about 0.5 seconds on a 
2011 MacBook Pro with a 2.3 GHz Core i7 processor). In addition to being printed to
the screen, the final fit is saved in a file called \texttt{bestfit\_parameters\_imfit.dat}.

The preceding command told \imfitprog{} to fit using every pixel in the image and to estimate
the noise assuming an original (previously subtracted) sky level of 130.14, an A/D gain
of 1.0, and zero read noise (the latter two are default values). A better approach would be 
to include a mask (telling \imfitprog{}
to ignore, e.g., pixels occupied by bright stars) and to specify more accurate values
of the gain and read noise:
\begin{quote}
\$ imfit ~ ic3478rss\_256.fits ~ \texttt{-c} ~ config\_sersic\_ic3478\_256.dat ~ \texttt{--}mask ~ ic3478rss\_256\_mask.fits ~ \texttt{--}gain=4.725 \texttt{--}readnoise=4.3 ~ \texttt{--}sky=130.14
\end{quote}

If you want to see what the best-fitting model looks like, you can use the companion program \makeimage{}
on the output file:
\begin{quote}
\$ makeimage ~ bestfit\_parameters\_imfit.dat ~ \texttt{--}refimage ~ ic3478rss\_256.fits
\end{quote}
This will generate and save the model image in a file called \texttt{modelimage.fits}. (The \imfitprog{}
program 
can itself save the best-fitting model image at the end of the fitting process if
the \texttt{--save-model} option is used.)

%Note that you can specify a subset of an image, thus:
%\begin{quote}
%ic3478rss\_256.fits[45:150,200:310]
%\end{quote}
%This will fit columns 45--150 and rows 200--310 of the image (column and row numbering starts
%at 1); pixel coordinates in the configuration (and output) files will refer to locations within the
%\textit{full} image.

You can also fit the image using PSF convolution, by adding the ``\texttt{--psf}'' option and a
valid \textsc{fits} image for the PSF; the \texttt{examples/} directory contains a Moffat PSF image which
matches stars in the original image fairly well:
\begin{quote}
imfit ~ ic3478rss\_256.fits ~ \texttt{-c} ~ config\_sersic\_ic3478\_256.dat ~ \texttt{--}mask ~ ic3478rss\_256\_mask.fits ~ \texttt{--}gain=4.725 \texttt{--}readnoise=4.3 ~ \texttt{--}sky=130.14 ~ \texttt{--}psf ~ psf\_moffat\_51.fits
\end{quote}


The PSF image was generated using \makeimage{} and the configuration
file \\
\texttt{config\_makeimage\_moffat\_psf.dat}:
\begin{quote}
\texttt{makeimage -o psf\_moffat\_51.fits config\_makeimage\_moffat\_psf.dat}
\end{quote}




\newpage

\chapter{Using \Imfit{}}\label{sec:using-imfit}\label{chap:using-imfit}

Basic use of \imfit{} from the command line looks like this:
\begin{quote}
  \texttt{\$ \imfitprog{} }  -c \textit{config-file} ~ \textit{input-image} ~ [options]
\end{quote}
where \textit{config-file} is the name of the configuration file
which describes the model (the combination of 2D functions, initial values
for parameters, and possible limits on parameter values) and \textit{input-image}
is the \textsc{fits} image we want to fit with the model. 

Note that both \textit{config-file} and \textit{input-image} -- as well
as other file names specified by options discussed below -- can be plain
filenames in the current working directory, relative paths (e.g.,
\texttt{data\_dir/image.fits}), or absolute paths.

The ``options'' are a set of command-line flags and options (use ``\imfitprog{} \texttt{-h}''
or ``\imfitprog{} \texttt{--help}'' to see the complete list). Options must be followed by
an appropriate value (e.g., a filename, an integer, a floating-point number); this can
be separated from the option by a space, or they can be connected with an equals sign.
In other words, both of the following are valid:
\begin{quote}
\imfitprog{} ~ \texttt{--}gain 2.5 \\
\imfitprog{} ~ \texttt{--}gain=2.5
\end{quote}
Note that \imfit{} does not follow the full \textsc{gnu} standard for
command-line options and flags (as implemented by, e.g., the \textsc{gnu}
\texttt{getopt} library): you cannot merge multiple one-character flags
into a single item (if ``\texttt{-a}'' and ``\texttt{-b}'' are flags,
``\texttt{-a -b}'' will work, but ``\texttt{-ab}'' will \textit{not}), and you
cannot merge a one-character option and its target
(``\texttt{-cfoo.dat}'' is \textit{not} a valid substitute for
``\texttt{-c foo.dat}'').


\section{Command-line Flags and Options}\label{sec:imfit-flags}

Some notable and useful command-line flags and options include:
\begin{itemize}
\item \texttt{-c, --config} \textit{config-file} -- the only \textit{required}
command-line option, which tells \imfitprog{} the name of the configuration file.
(Actually, if you don't supply this option, \imfitprog{} will look for a file
called ``imfit\_config.dat'', but it's best to explicitly specify your own
configuration files.)

\bigskip

\item \texttt{--psf} \textit{psf-image} -- specifies a \textsc{fits} image to be convolved
with the model image.

\bigskip

\item \texttt{--overpsf} \textit{psf-image} -- specifies an oversampled
\textsc{fits} image to be convolved with (a subregion of) the model image.

\item \texttt{--overpsf\_scale} \textit{scale} -- specifies the oversampling
factor of the oversampled PSF image (an integer $> 1$). E.g., for a $5 \times 5$
oversampled PSF image (25 PSF pixels for each data-image pixel), the scale is 5.

\item \texttt{--overpsf\_region} \textit{x1:x2,y1:y2} -- specifies the
subsection of the image where oversampled PSF convolution will be done.
Multiple oversampled regions (each convolved with the same oversampled
PSF) can be specified by repeating this command.

\bigskip

\item \texttt{--mask} \textit{mask-image} -- specifies a \textsc{fits} image which marks
bad pixels to be ignored in the fitting process. By default, zero values in
the mask indicate \textit{good} pixels, and positive values indicate bad pixels.
\item \texttt{--mask-zero-is-bad} -- indicates that zero values (actually,
any value $< 1.0$) in the mask correspond to \textit{bad} pixels, with values
$\geq 1.0$ being good pixels.

\bigskip

\item \texttt{--noise} \textit{noisemap-image} -- specifies a pre-existing noise
or error \textsc{fits} image to use in the \chisquare{} fitting process (by default, pixel values in the
noise map are assumed to be Gaussian $\sigma$ values).
\item \texttt{--errors-are-variances} -- indicates that pixel values in the noise
map are variances ($\sigma^2$) instead of sigmas.
\item \texttt{--errors-are-weights} -- indicates that pixel values in the noise
map should be interpreted as weights (e.g., $1/\sigma^2$), not as sigmas or variances. (None
of these three options is usable with Cash statistic or Poisson-MLR statistic minimization.)

\bigskip

\item \texttt{--sky} \textit{sky-level} -- specifies an original
constant sky background level (in counts/pixel) \textit{that was
previously subtracted from the image}; this is used for internal
computation of the noise map (for \chisquare{} minimization) or for
correcting the Cash statistic or Poisson-MLR statistic computation. (If
the units of the pixel values are counts/sec, then the sky level should
also be in those units, and you should use the ``\texttt{--exptime}''
option to specify the original exposure time.)

\item \texttt{--gain} \textit{value} -- specifies the A/D gain (in electrons/ADU)
of the input image; used for internal computation of the noise map (for \chisquare{}
minimization) or for correcting the Cash statistic and Poisson-MLR statistic computation.

\item \texttt{--readnoise} \textit{value} -- specifies the read noise (in electrons)
of the input image; used for internal computation of the noise map for \chisquare{}
minimization (this is ignored in the case of Cash statistic or Poisson-MLR statistic minimization).

\item \texttt{--exptime} \textit{value} -- specifies the exposure time of the image;
this should \textbf{only} be used \textit{if} the image has been divided by the exposure time
(i.e., if the pixel units are counts/sec).

\item \texttt{--ncombined} \textit{value} -- if values in the input
image are the result of averaging (or computing the median of) two or
more original images, then this option should be used to specify the
number of original images; this is used for internal computation of the noise map (for \chisquare{}
minimization) or for correcting the Cash statistic and Poisson-MLR statistic computation.  
If multiple images were \textit{added} together with no rescaling, then do not use this option.

\bigskip

\item \texttt{--save-params} \textit{output-filename} -- specifies that parameters 
for best-fitting model should be saved using the specified filename (the default is
for these to be saved in a file named \texttt{bestfit\_parameters\_imfit.dat}).
\item \texttt{--save-model} \textit{output-filename} -- the best-fitting model image
will be saved using the specified filename.
\item \texttt{--save-residual} \textit{output-filename} -- the residual image (input
image $-$ best-fitting model image) will be saved using the specified filename.

\bigskip

\item \texttt{--nm} -- use Nelder-Mead simplex instead of Levenberg-Marquardt as
the minimization technique (\textsc{Warning}: slower)

\item \texttt{--de} -- use Differential Evolution instead of Levenberg-Marquardt as
the minimization technique (\textsc{Warning}: much slower!)

\item \texttt{--de-lhs} -- use Differential Evolution with Latin hypecube sampling
(as opposed to standard uniform sampling) for the initial guesses

\item \texttt{--nlopt} \textit{algorithm-name} -- use one of the
``local derivative-free'' minimization algorithms from the NLopt
library;\footnote{See
\url{https://nlopt.readthedocs.io/en/latest/NLopt_Algorithms/}.}
recognized options are COBYLA, BOBYQA, NEWUOA, PRAXIS, and SBPLX. These
are generally slower and/or less robust than the Nelder-Mead simplex
algorithm (which is also part of the NLopt library, and can be specified
with \texttt{--nlopt NM}, though it's simpler just to use \texttt{--nm}).

\bigskip

\item \texttt{--model-errors} -- use the model image pixel values
(instead of the data values) to estimate the individual-pixel dispersions
$\sigma_{i}$ for \chisquare{} minimization

\item \texttt{--cashstat} -- use Cash statistic $C$ instead of \chisquare{}
as the fit statistic for minimization. This is especially useful in the
case of Poisson statistics and low or zero read noise, but it also provides less
biased fits than the \chisquare{} approach even when count levels are
high. Cannot be used with the (default) Levenberg-Marquardt minimization
technique.

\item \texttt{--poisson-mlr} or \texttt{-mlr} -- like \texttt{--cashstat}, but uses the
Poisson Maximum-Likelihood-Ratio statistic for minimization (this is
the same as the ``CSTAT'' statistic in the X-ray packages XSPEC and
Sherpa); fits should be essentially identical. The main difference is that this statistic is
always $\ge 0$, which means it \textit{can} be used with the (default)
Levenberg-Marquardt minimization technique.

\item \texttt{--ftol} \textit{FTOL-value} -- specify tolerance for
fractional improvements in the fit statistic value; if further iterations do 
not reduce the fit statistic by more than this, the minimization is considered a 
success and halted (default value = $10^{-8}$)

\bigskip

\item \texttt{--bootstrap} \textit{n-iterations} -- Do \textit{n-iterations} rounds
of bootstrap resampling after the fit, to estimate parameter errors.

\item \texttt{--save-bootstrap} \textit{filename} -- file to save
individual best-fit parameter values from the bootstrap resampling (one
line per iteration).

\bigskip

\item \texttt{--quiet} -- Suppress printing of intermediate fit-statistic values
during the fitting process.

\item \texttt{--loud} -- Print intermediate parameter values during the fitting
process. Currently applicable to L-M fitting (current best-fit parameter values are
printed once per iteration) and N-M simplex fitting (best-fit values printed once per 100 interations).

\bigskip

\item \texttt{--chisquare-only} or \texttt{--fitstat-only} (these are
synonyms) -- Evaluate the \chisquare{} value for the initial input
model as a fit to the input image, \textit{without} doing any
minimization to find a better solution. (If \texttt{--cashstat} or
\texttt{--poisson-mlr} is also specified, then the appropriate 
statistic is evaluated instead.)

\bigskip

\item \texttt{--max-threads} \textit{n-threads} -- specifies the maximum number of CPU cores to use
during computation (the default is to use \textit{all} available CPU cores); has no
effect if \imfit{} was compiled without OpenMP or \textsc{fftw} multithreading support.

\item \texttt{--seed} \textit{N} -- specifies a specific integer seed to use with
random number generation; applies to DE fits and also to bootstrap resampling. This is
mainly for testing purposes, to ensure that the same sequence of pseudo-random
numbers is generated. (By default, the current system time is used as a seed,
ensuring that no two runs have the same random seed.)

\bigskip

\item \texttt{--sample-config} -- generates and saves a simple example
of an \imfit{} configuration file (named
\texttt{config\_imfit\_sample.dat}).

\item \texttt{--list-functions} -- list all the functions \imfit{} can use.

\item \texttt{--list-parameters} -- list all the individual parameters (in correct order)
for each of the functions that \imfit{} can use. You can copy and paste pieces of the output
of this command to help construct a configuration file.
\end{itemize}




\newpage

\chapter{The Configuration File}\label{sec:configfile}

\Imfit{} always requires a configuration file, which specifies the model
which will be fit to the input image, initial values for model parameters, any
limits on parameter values (optional for fitting with the Levenberg-Marquardt
solver, but required for fitting with the Differential Evolution solver), and
possibly additional information (e.g, gain and read noise for the input image).

The configuration file should be a plain text file. Blank lines and
lines beginning with ``\#'' are ignored; in fact, anything on the same line after a
``\#'' is ignored, which allows for comments at the end of lines. (A minor exception:
on lines defining a function name, an optical label can be specified as part
of the comment.)

A model for an image is specified by one or more \textbf{function sets},\footnote{In
versions of \Imfit{} prior to 1.8, these were generally referred to as ``function 
blocks''.} each of
which is a group of one or more 2D image functions sharing a common $(x,y)$
spatial position. Each function-specification consists of a line beginning with
``FUNCTION'' and containing the function name, followed by one or more lines
with specifications for that function's parameters.

\bigskip

More formally, the format for a configuration file is:
\begin{enumerate}
\item Optional specifications of general parameters and settings (e.g., the
input image's A/D gain and read noise)
\item One or more function sets, each of which contains:
\begin{enumerate}
\item X-position parameter-specification line
\item Y-position parameter-specification line
\item One or more function + parameters specifications, each of which contains:
\begin{enumerate}
\item \texttt{FUNCTION} + function-name line [+ optional label]
\item one or more parameter-specification lines
\end{enumerate}
\end{enumerate}
\end{enumerate}

This probably sounds more complicated than it is in practice.
Here is a very bare-bones example of a configuration file:

\begin{quote}
  \texttt{X0  ~  150.1}\\
  \texttt{Y0  ~  149.5}\\
  \texttt{FUNCTION   Exponential}\\
  \texttt{PA  ~  95.0}\\
  \texttt{ell  ~  0.45}\\
  \texttt{I\_0 ~  90.0}\\
  \texttt{h   ~  15.0}\\
\end{quote}

This describes a model consisting of a single elliptical exponential
function, with initial values for the $x$ and $y$ position on the image
of the object's center, the position angle (PA), the ellipticity (ell),
the central intensity (I\_0) in counts/pixel, and the exponential scale
length in pixels (h). None of the parameters have limits on their
possible values.

Here is the same file, with some additional annotations and with limits on
some of the parameters (comments are colored red for clarity):

\begin{quote}
  \texttt{\red{\# This line is a comment}}\\
  
  \texttt{X0 ~~   150.1 ~  148,152}\\
  \texttt{Y0 ~~   149.5 ~  148,152         \red{\# a note}}\\
  \texttt{FUNCTION   Exponential  ~ \red{\# here is a comment}}\\
  \texttt{PA  ~  95.0  ~ 0,180   ~~   \red{\# limits on the position angle}}\\
  \texttt{ell  ~  0.45 ~ 0,1     ~~~ \red{\# ellipticity should always be 0--1}}\\
  \texttt{I\_0 ~  90.0 ~  fixed ~~~ \red{\# keep central intensity fixed}}\\
  \texttt{h    ~ 15.0}\\
\end{quote}

Here we can see the use of comments (lines or parts of lines beginning with
``\#'') and the use of parameter limits in the form of ``lower,upper'': the X0
and Y0 parameters are required to remain $\geq 148$ and $\leq 152$, the position
angle is limited to 0--180, the ellipticity must stay $\geq 0$ and $\leq 1$, and
the central intensity I\_0 is held fixed at its initial value.

Finally, here is a more elaborate example, specifying a model that has two
function sets, with the first set having two individual functions (this
could be a model for, e.g., simultaneously fitting two galaxies in the same
image, one as S\'ersic + exponential, the other with just an exponential).
In addition, we specify labels for the two functions. These labels are
purely for the convenience of the user; they have no
effect on the fitting, but are reproduced in output files.

\begin{quote}
  \texttt{\red{\# This line is a comment}}\\
  
  \texttt{GAIN  2.7   \red{\# A/D gain for image in e/ADU}}\\
  \texttt{READNOISE  4.5   \red{\# image read-noise in electrons}}\\
  
  \texttt{\red{\# This is the first function set: Sersic + exponential}}\\
  \texttt{X0 ~~   150.1  ~~ 148,152}\\
  \texttt{Y0 ~~   149.5  ~~ 148,152}\\
  \texttt{FUNCTION   Sersic   \red{\# LABEL galaxy 1 bulge}}\\
  \texttt{PA  ~  95.0  ~~ 0,180}\\
  \texttt{ell ~   0.05 ~ 0,1}\\
  \texttt{n   ~~   2.5  ~~~ 0.5,4.0 ~~ \red{\# Sersic index}}\\
  \texttt{I\_e ~  20.0 ~~ \red{\# intensity at the half-light radius}}\\
  \texttt{r\_e ~    5.0 ~~ \red{\# half-light radius in pixels}}\\
  \texttt{FUNCTION   Exponential   \red{\# LABEL galaxy 1 disk}}\\
  \texttt{PA   ~ 95.0  ~~ 0,180}\\
  \texttt{ell  ~  0.45  ~~0,1}\\
  \texttt{I\_0 ~  90.0  ~ fixed}\\
  \texttt{h    ~~ 15.0}\\
  
  \texttt{\red{\# This is the second function set: just a single exponential}}\\
  \texttt{X0 ~~   225.0  ~~ 224,226}\\
  \texttt{Y0 ~~   181.7  ~~ 180,183}\\
  \texttt{FUNCTION   Exponential   \red{\# LABEL galaxy 2}} \\
  \texttt{PA   ~ 22.0  ~~ 0,180      }\\
  \texttt{ell  ~  0.25 ~ 0,1}\\
  \texttt{I\_0 ~  10.0  }\\
  \texttt{h   ~~~  20.0}\\
\end{quote}


\section{Parameter Names, Specifications, and Values}

The X0/Y0 position lines at the start of each function set and the
individual parameter lines for each function all share a common format:
\begin{quote}
\textit{parameter-name} ~~ \textit{initial-parameter-value} ~~ \textit{optional-limits}
\end{quote}
The separation between the individual pieces must consist of one or more spaces
and/or tabs. The final piece specifying the limits is optional (except that
fitting in Differential Evolution mode \textit{requires} that there be limits
for each parameter).

\bigskip

\textbf{Parameter Names:} The X0/Y0 positional parameters for each
function set must be labeled ``X0'' and ``Y0''. Names for the
parameters of individual functions can be anything the user desires;
only the order matters. Thus, the position-angle parameter could be
labeled ``PA'', ``PosAngle'', ``angle'', or any non-space-containing
string -- though it's a good idea to have it be something relevant
and understandable.

\textbf{Important Note:} \textit{Do not change the order of the parameters
for a particular function!}  Because the strings giving the parameter names
can be anything at all, \imfitprog{} actually ignores them and simply assumes
that all parameters are in the correct order for each function.

Note that any output which \imfitprog{} generates will use the default parameter
names defined in the individual function code (use ``\texttt{--list-parameters}''
to see what these are for each function).

\bigskip

\textbf{Values for Positional Parameter (X0, Y0)}: The positional parameters
for each function set are pixel values -- X0 for the column number and
Y0 for the row number. \Imfit{} uses the \textsc{iraf} pixel-numbering
convention: the center of first pixel in the image (the lower left pixel
in a standard display) is at $(1.0,1.0)$, with the lower-left corner of that
pixel having the coordinates $(0.5,0.5)$.

Note that these positions are in the coordinate system of the entire
image. That is, if you specify a subsection of the image to be fit
(e.g., ``image.fits[150:350,425:700]''), the X0 and Y0 values must still
be absolute positions referring to the original image, \textit{not} relative
positions with the subsection.


\bigskip

\textbf{General Parameter Values for Functions}: The meaning of the individual
parameter values for the various 2D image functions is set by the functions
themselves, but in general: 
\begin{itemize}
\item position angles are measured in degrees counter-clockwise
from the image's vertical ($+y$) axis (i.e., degrees E of N if the image has standard
astronomical orientation);
\item ellipticity $= 1 - b/a$, where $a$ and $b$ are the
semi-major and semi-minor axes of an ellipse;
\item intensities are in counts/pixel;
\item lengths are in pixels. 
\end{itemize}
If you write your own functions, you are encouraged
to stick to these conventions.

\section{Parameter Limits}\label{sec:param-limits}

Individual parameters can be limited in two ways:
\begin{enumerate}
\item Held fixed;
\item Bounded between lower and upper limits.
\end{enumerate}
To hold a parameter fixed, use the string ``fixed'' after the initial-value
specification. E.g.:
\begin{quote}
\texttt{X0} ~~ 442.85 ~~ fixed
\end{quote}
To specify lower and upper limits for a parameter, include them as a comma-separated
pair following the initial-value specification. E.g.:
\begin{quote}
\texttt{X0} ~~ 442.85 ~~ 441.0,443.5
\end{quote}
Note that specifying \textit{equal} lower and upper limits for a parameter (or a lower limit
which is higher than the upper limit) is not allowed; to specify that a parameter
value should remain constant, used the ``fixed'' keyword as described above.
\textbf{Warning:} there should be \textit{no} spaces before or after the comma. E.g., use ``441.0,443.5'',
not ``441.0,~443.5'' or ``441.0~,~443.5''.


\section{Function Labels}

Optional labels can be attached to each function. This has no effect on the fits,
but since the labels are copied to the output printouts and files, they can be
helpful in cases where models become complicated.

The basic idea is a comment is added after the function name, where the first
non-whitespace element after the comment character is the word ``LABEL'' (must
be in all-caps), followed by whitespace, and then the rest of the line is
treated as the label.

\begin{quote}
\texttt{FUNCTION} ~ \textit{function-name} ~ \texttt{\#} ~ \texttt{LABEL} ~ \textit{label-text}
\end{quote}

For example,

\begin{quote}
\texttt{FUNCTION Exponential} ~ \texttt{\#} ~ \texttt{LABEL nuclear disk}
\end{quote}


\section{Optional Image-Description Parameters}

The configuration file can, optionally, contain one or more specifications of 
parameters describing the whole image, which take the place of certain command-line
options for computing the internal noise map.  The specifications should be placed
\textit{at the beginning} of the configuration file, \textit{before} the first function
set is described. The format is the same as for other parameters in the configuration
file: the name of the parameter, followed by one or more spaces and/or tabs, followed
by a numerical value. E.g.,
\begin{quote}
  \texttt{GAIN  2.7} \\
  \texttt{READNOISE  4.5} \\
\end{quote}

The currently available image-description parameters are (see Section~\ref{sec:imfit-flags} for more
details about the corresponding command-line options):
\begin{itemize}
\item GAIN -- same as command-line option \texttt{--gain} (A/D gain in electrons/ADU)
\item READNOISE -- same as command-line option \texttt{--readnoise} (read noise in electrons)
\item EXPTIME -- same as command-line option \texttt{--exptime}
\item NCOMBINED -- same as command-line option \texttt{--ncombined}
\item ORIGINAL\_SKY -- same as command-line option \texttt{--sky} (original
background level that was subtracted from the image)
\end{itemize}

In situations where a configuration file contains one of these specifications
and the corresponding command-line option is also used, \textit{the command-line option
always overrides whatever value is  in the configuration file.}



\newpage

\chapter{Standard Image Functions}

\Imfit{} comes with the following 2D image functions, each of
which can be used as many times as desired. (As mentioned above, \imfit{}
is designed so that constructing and using new functions is a relatively
simple process.) Most of these functions use a specified radial intensity
profile (e.g., Gaussian, exponential, S{\'e}rsic) with elliptical isophote
shapes. Note that elliptical functions can always be made circular
by setting the ``ellipticity'' parameter to 0.0 and specifying that it be
held fixed. See Appendix~\ref{app:functions} for more complete discussions of all
functions, including their parameters.

\begin{itemize}
\item FlatSky -- a uniform sky background.
\item TiltedSkyPlane -- a sky background in the form of an inclined plane.
\item Gaussian -- an elliptical 2D Gaussian function.
\item Moffat -- an elliptical 2D Moffat function.
\item Exponential -- an elliptical 2D exponential function.
\item Exponential\_GenEllipse -- an elliptical 2D exponential function using
generalized ellipses (``boxy'' to ``disky'' shapes) for the isophote shapes.
\item Sersic -- an elliptical 2D S\'ersic function.
\item Sersic\_GenEllipse -- an elliptical 2D S\'ersic function using
generalized ellipses (``boxy'' to ``disky'' shapes) for the isophotes.
\item Core-Sersic -- an elliptical 2D Core-S\'ersic function \citep{graham03,trujillo04}.
\item BrokenExponential -- similar to Exponential, but with \textit{two}
exponential radial zones (with different scalelengths) joined by a transition region
at $R_{\mathrm{break}}$ of variable sharpness.
\item GaussianRing -- an elliptical ring with a radial profile
consisting of a Gaussian centered at $r = R_{\mathrm{ring}}$.
\item GaussianRing2Side -- like GaussianRing, but with a radial profile
consisting of an asymmetric Gaussian (different values of $\sigma$ for
$r < R_{\mathrm{ring}}$ and $r > R_{\mathrm{ring}}$).
\item GaussianRingAz -- like GaussianRing, but the peak intensity of the
radial Gaussian profile varying (sinusoidally) with azimuth.
\item EdgeOnDisk -- the analytical form for a perfectly edge-on exponential
disk, using the Bessel-function solution of \citet{vdk81} for 
the radial profile and the generalized sech function of \citet{vdk88} 
for the vertical profile.
\item EdgeOnRing -- a simplistic model for an edge-on ring, using a
Gaussian for the radial profile and another Gaussian (with
different $\sigma$) for the vertical profile.
\item EdgeOnRing2Side -- like EdgeOnRing, but using an
asymmetric Gaussian for the radial profile (see description of GaussianRing2Side).
\item FerrersBar2D -- a 2D version of the Ferrers ellipsoid.
\item FlatBar -- An ad-hoc description of the outer (vertically thin) part of a
relatively face-on bar in a massive galaxy (with the ``flat'' radial profile first
identified by \cite{ee85}).

\end{itemize}

In addition, four ``3D'' functions are available. With these, the
intensity value for each pixel comes from line-of-sight integration
through a 3D luminosity-density model, generating a projected 2D model
image given input specifications of the orientation and inclination to
the line of sight.
\begin{itemize}
\item ExponentialDisk3D -- uses a 3D luminosity-density model of an axisymmetric 
exponential disk (with different radial and vertical scale lengths), observed
at an arbitrary inclination, to generate a projected surface-brightness image.
\item BrokenExponentialDisk3D -- similar to ExponentialDisk3D, except that the
radial profile of the luminosity density is a broken exponential.

\item GaussianRing3D -- uses a 3D luminosity-density model of an
elliptical ring with Gaussian radial and exponential vertical profiles.

\item FerrersBar3D -- uses a 3D luminosity-density model of a triaxial
\citet{ferrers} ellipsoid.

\end{itemize}

A list of the currently available functions can always be obtained
by running \imfitprog{} with the ``\texttt{--list-functions}'' option:
\begin{quote}
  \texttt{\$ \imfitprog{} --list-functions}
\end{quote}
The complete list of function parameters for each function (suitable for copying
and pasting into a configuration file) can always be
obtained by running \imfitprog{} with the ``\texttt{--list-parameters}'' option:
\begin{quote}
  \texttt{\$ \imfitprog{} --list-parameters}
\end{quote}




\newpage

\chapter{Images}

\Imfit{} is designed to fit 2D astronomical images in \textsc{fits}
format, where pixel values are some form of linear surface-brightness
(or surface density) measurement. The default internal error
calculations (see Section~\ref{sec:noise-maps}, below) assume that pixel
values are integrated counts (e.g., ADUs), which can be converted to
detected photons using the $A/D$ gain (provided by the 
``\texttt{--gain}'' option, or by the GAIN keyword in a configuration
file). However, since \imfit{} can also accept a user-supplied
noise/error image in \textsc{fits} format, you can use any linear pixel
values as long as the corresponding noise image is appropriately scaled
to match (and you're using \chisquare{} statistics).

If your image is in counts/second, you can either multiply it by the
exposure time to recover the integrated counts, or include the actual
exposure time via the ``\texttt{--exptime}'' option (or the EXPTIME keyword
in a configuration file).

If the image is an \textit{average} of $N$ input images of the same exposure time, you
can either multiply the image by $N$ \textit{or} use the ``\texttt{--ncombined}'' option
to tell \imfit{} how to adjust the error estimations.  The latter option is slightly
better, because \imfit{} will also scale the read noise accordingly (if \chisquare{}
statistics are being used and the read noise is nonzero).

\Imfit{} does \textit{not} assume the presence of any particular header
keywords in the \textsc{fits} file.




\section{Specifying Image Subsections, Compressed Images, etc.}

\subsection{Image Subsections}

In many cases, you may want to fit an object which is much smaller than the whole
image. You can always make a smaller cutout image and fit that, but it may be convenient to
specify the image subsection directly. You can do this using a subset of the image-section
syntax of \textsc{cfitsio} (which will be familiar to you if you've ever worked with
image sections in \textsc{iraf}). An example:
\begin{quote}
ic3478rss\_256.fits[45:150,200:310]
\end{quote}
This will fit columns 45--150 and rows 200--310 of the image (column and
row numbering starts at~1 and is inclusive, so ``[1:10]'' means column or
row numbers 1 through 10). Pixel coordinates in the configuration (and
output) files refer to locations within the \textit{full} image, not
relative positions within the subsection. Note that this works as-is
when running \Imfit{} from within the Bash shell; for the C shell, you
may need to enclose the image name + specification in quotation marks.

The only kind of image section specification that's allowed is a simple
[x1:x2,y1:y2] format, though you can specify all of a particular dimension using
an asterisk (e.g., [*,y1:y2] to specify the full range of x values). Exception:
you can also specify an image extension number for a multi-extension \textsc{fits} file;
see below.

Obviously, if you are also using a mask image (and/or a noise image), you should
specify the same subsection in those images!


\subsection{Image Extensions; Compressed Files}

By default, \Imfit{} will try to read the first (``primary'') Header
Data Unit (HDU) in a \textsc{fits} file. If this is \textit{not} a
proper 2D image -- e.g, if it is an empty, header-only HUD; if it is a
1D spectrum; if it is a table; etc.\ -- then \Imfit{} will report an
error and quit.

You \textit{can} specify a particular extension in a multi-extension
\textsc{fits} file using the \textsc{cfitsio} format, e.g.:

\begin{quote}
ic3478rss.fits[2]

ic3478rss.fits[2][45:150,200:310]
\end{quote}

This particular numbering scheme is zero-based: the primary HDU is 0, the
first extension (which is the second HDU) is 1, etc.

You can also fit (or generate) images which have been compressed with
gzip or Unix compress -- e.g., \texttt{ic3478rss\_256.fits.gz}. Images,
masks, etc., can even be read via \texttt{http://} or \texttt{ftp://}
URLs which point directly to accessible \textsc{fits} files; you cannot
\textit{save} files to URLs, however.



\newpage

\chapter{Extras for Fitting Images}

\section{Masks (and automatic masking of certain pixels)}

A mask image can be supplied to \imfitprog{} by using the command-line
option \texttt{--mask}. The mask image should be an
\textit{integer}-valued \textsc{fits} file with the same dimensions as
the image being fitted (\textsc{iraf} \texttt{.pl} mask files are not
recognized, but these can be converted to \textsc{fits} format within
\textsc{iraf}). The default is to treat zero-valued pixels in the mask
image as \textit{good} and pixels with values $> 0$ as \textit{bad}
(i.e., to be excluded from the fit); however, you can specify that
zero-valued pixels are \textit{bad} with the command-line flag
\texttt{--mask-zero-is-bad}.

Any pixels in the data image, the noise/error/weight image (see below),
\textit{or} the mask image which have non-finite values (i.e., NaN,
$\pm\infty$) will automatically be considered part of the mask (i.e.,
corresponding pixels in the data image will be excluded from the fit).


\section{Noise, Variance, or Weight Maps}\label{sec:noise-maps}

(See Section~\ref{sec:fit-statistics} for background on the different fit statistics.)

By default, \imfitprog{} uses \chisquare{} as the statistic for
minimization. As part of this process, \imfitprog{} normally calculates an internal
weight map, using the input pixel intensities, the A/D gain, any
previously subtracted background level, and the read noise to estimate
Gaussian errors $\sigma_{i}$ for each pixel $i$. In formal terms, the error-based weight
map is $w_{i} = 1/\sigma^{2}_{i}$, with the dispersion (in ADU) defined as
\begin{equation}
\sigma^{2}_{i} \; = \; (I_{d, i} + I_{\mathrm{sky}})/g_{\mathrm{eff}} \, + \, N_{\mathrm{c}} \, \sigma_{\mathrm{rdn}}^{2}/g_{\mathrm{eff}}^{2} \, ,
\end{equation}
where $I_{d, i}$ is the data intensity in counts/pixel,
$I_{\mathrm{sky}}$ is the original subtracted sky background (if any),
$\sigma_{\mathrm{rdn}}$ is the read noise (in electrons),
$N_{\mathrm{c}}$ is the number of separate images combined (averaged or
median) to form the data image, and $g_{\mathrm{eff}}$ is the
``effective gain'' (the product of the $A/D$ gain,  $N_{\mathrm{c}}$,
and optionally the exposure time, if the pixel units are counts/sec).
As an alternative, the \textit{model} intensity values $I_{m, i}$ can be
used instead of $I_{d, i}$, by specifying the \texttt{--model-errors}
command-line flag. This is marginally slower (since the weights must be
recalculated every time the model image is updated), but can lead to
smaller biases in fitted parameters \citep[see][]{humphrey09,erwin15}.

The weights are then used in the \chisquare{} calculation:
\begin{equation}
\chisquare \; = \; \sum_{i = 0}^{N} w_{i} \, (I_{m, i} - I_{d, i})^2 ,
\end{equation}
where $I_{m, i}$ and $I_{d, i}$ are the model and data intensities
in counts/pixel, respectively. (Masking is handled by setting $w_{i} = 0$
for masked pixels.)

If you have a pre-existing error map as a \textsc{fits} image, you can tell \imfitprog{} to
use that instead, via the \texttt{--noise} command-line option. By default, the
pixel values in this image are assumed to be errors $\sigma_{i}$ in units of
ADU/pixel. If the values are \textit{variances} ($\sigma_{i}^2$), you can specify
this with the \texttt{--errors-are-variances} flag. You can also tell \imfitprog{}
that the pixel values in the noise map are actual \textit{weights} $w_{i}$ (e.g.,
if the values are inverse variances) via the
\texttt{--errors-are-weights} flag, if that happens to be the case. (If a mask
image is supplied, the weights of masked pixels will still be set to 0,
regardless of their individual values in the weight image.)

Internally, the weight map for \chisquare{} calculations is actually stored using
the \textit{square root} $\sqrt{w_{i}}$ of the weights as defined above. This is because the
Levenberg-Marquardt solver relies on access to a vector of ``deviate'' values, which are
the square roots of individual terms in the formal \chisquare{} sum:
\begin{equation}
\sqrt{w_{i}} \, (I_{m, i} - I_{d, i}) .
\end{equation}

\textbf{Important Note:} Prior to version 1.3, \imfitprog{} incorrectly
interpreted the \texttt{--errors-are-weights} flag as indicating that
the pixel values of the input ``noise map'' were $\sqrt{w_{i}}$, and the
\texttt{--save-weights} option caused \imfitprog{} to output a \textsc{fits} file with
$\sqrt{w_{i}}$ values. Starting with version 1.3, \imfitprog{} treats those two
commandline-flags/options as referring to $w_{i}$ as defined above, and
conversions to and from the internal $\sqrt{w_{i}}$ values are handled
correctly.

\bigskip

In the case of minimizing the Poisson-MLR statistic or the related Cash statistic $C$, the 
only relevant external maps are masks. For the Cash statistic $C$, the actual minimized 
quantity is:
\begin{equation}
C \; = \; 2 \sum_{i = 0}^{N} w_{i} \, (I^{\prime}_{m, i} \, - \, I^{\prime}_{d, i} \ln I^{\prime}_{m, i}),
\end{equation}
where $I^{\prime}_{m, i}$ and $I^{\prime}_{d, i}$ are the model and data
intensities in counts/pixel, multiplied by the effective gain $g_{\mathrm{eff}}$ as defined 
above.  In this case, all weights are automatically $=1$, except for masked pixels, which 
are still set $= 0$. (Note that any attempt to specify the read noise is ignored, since 
Gaussian noise terms cannot be accommodated in the Cash-statistic or Poisson-MLR statistic
computation; see, e.g., \citealt{erwin15}.)

The Poisson-MLR statistic includes extra terms based on the data values:
\begin{equation}
\mathrm{\pmlr} \; = \;  2 \sum_{i = 1}^{N} w_{i} \, 
\left( I^{\prime}_{m, i} - I^{\prime}_{d, i} \ln I^{\prime}_{m, i} + I^{\prime}_{d, i} \ln I^{\prime}_{d, i} - I^{\prime}_{d, i} \right).
\end{equation}

\medskip

Note that \imfitprog{} does \textit{not} try to obtain information (such as
the A/D gain or read noise) from the \textsc{fits} header of an image. This is primarily
because there is little consistency in header names across the wide range of
astronomical images, so it is difficult pick one name, or even a small set, and
assume that it will be present in a given image's header; this is even more
true if an image is the result of a simulation.




\section{PSF Convolution (Including Oversampled PSFs)}

To simulate the effects of seeing and other telescope resolution effects, model
images can be convolved with a PSF (point-spread function) image. This uses an
input \textsc{fits} file which contains the point spread function. The actual convolution
uses Fast Fourier Transforms of the internally-generated model image and the PSF
image to compute the output convolved model image.

PSF images should be square, ideally with width $N$ = an odd number of
pixels, and the PSF should be centered in the central pixel: $x = y = N \,
\mathbf{div} \, 2 \, + \, 1$, where $\mathbf{div}$ is integer division (remember
that \imfit{} uses the \textsc{iraf}/DS9 convention for pixel numbering: the center
of the first pixel in the image is at $(x,y) = (1.0,1.0)$, etc.).
E.g., for a $25 \times 25$-pixel PSF, the center should be at $(x,y) =
(13.0,13.0)$. An off-center PSF can certainly be used, but the resulting
convolved model images will be shifted! The PSF does \textit{not} need
to be normalized, as \imfitprog{} will automatically normalize the PSF
image internally.

Although \imfit{} uses a multi-threaded version version of the
\textsc{fftw} library, which is itself quite fast, adding PSF
convolution to the image-fitting process \textit{does} slow things down
considerably.


\subsection{Convolution with Oversampled PSFs}

The default convolution performed by \imfit{} uses a PSF image and a
model image which have the same spatial scaling as the data image. While
this is adequate for most purposes, it is a somewhat crude approximation
to the true situation, since in reality the PSF convolution process is
effectively infinite-resolution and takes place prior to the sampling
of the image in pixel space by the detector.

A better approach would be to construct a model image at higher resolution
and convolve it with a higher-resolution PSF, then downsample the resulting
image to the same pixel scale as the data image. Unfortunately, this can be
quite time-consuming (and memory-consuming), due to the larger
images required. 

A compromise is to perform a standard convolution on the entire image, and
then replace a small subset of the model image (e.g., around a bright
point source where more accurate PSF convolution is desirable) with the
result of a higher-resolution convolution. This can be done in \imfit{}
with the ``\texttt{overpsf}'' command-line options.

To convolve an image region with an oversampled PSF, you need to use \textit{three}
command-line options:
\begin{itemize}
\item \texttt{--overpsf} to specify the FITS file which holds the oversampled PSF image;
\item \texttt{--overpsf\_scale} to specify the \textit{amount} of oversampling corresponding
to the PSF image (i.e., how many oversampled pixels fit into an original pixel along
one axis; this must be an integer);
\item \texttt{--overpsf\_region} to specify what part of the image should have convolution
with the oversampled PSF applied to the model.
\end{itemize}
For example, 
\begin{quote}
\texttt{\$ imfit --overpsf psf5.fits --overpsf\_scale 5 \textbackslash \\
         --overpsf\_region 490:500,620:630}
\end{quote}
tells \imfit{} that you want the region [490:500,620:630] within the
image to use oversampled PSF convolution, that the oversampled PSF is
contained in the file \texttt{psf5.fits}, and that the oversampling
scale is a factor of 5 (i.e., one normal pixel in the image corresponds
to $5 \times 5$ pixels in the oversampled model and the PSF).

As is true for the X0 and Y0 parameter values, the oversampled-region
specification refers to the coordinate system of the entire input image,
\textit{not} relative coordinates within a subsection.

More than one oversampled region can be specified by repeating the 
\texttt{--overpsf\_region} command; this will use the same oversampled
PSF and oversampling scale.

In some cases, one may wish to use \textit{different} oversampled PSF
images for different parts of the image, particularly if it is known
that the PSF varies significantly across the image (and if one has
representative oversampled PSF images). In this case, multiple
oversampled PSF images (with, potentially, different oversampling
scales) can be specified, each with its corresponding image region. To
do this, extra invocations of the \texttt{--overpsf} and
\texttt{--overpsf\_scale} commands should be given, along with one
\texttt{--overpsf\_region} per oversampled PSF.

To summarize, one can do the following with \imfitmcmc, \imfitmcmc, or \makeimage:
\begin{enumerate}
\item Convolve one subsection of the model image with an oversampled PSF image, e.g.
\begin{quote}
\texttt{ --overpsf=oversampled\_psf.fits --overpsf\_scale=4 \textbackslash \\
		--overpsf\_region=200:205,260:265}
\end{quote}

\item Convolve several subsections of the model image with the same oversampled
PSF image, e.g.
\begin{quote}
\texttt{ --overpsf=oversampled\_psf.fits --overpsf\_scale=4 \textbackslash \\
		--overpsf\_region=200:205,260:265 --overpsf\_region=310:315,581:590}
\end{quote}

\item Convolve several subsections of the model image, each with a different
oversampled PSF image.
\begin{quote}
\texttt{ --overpsf=oversampled\_psf1.fits --overpsf\_scale=4 \textbackslash \\
		--overpsf\_region=200:205,260:265  \textbackslash \\
		--overpsf=oversampled\_psf2.fits --overpsf\_scale=4 \textbackslash \\
		--overpsf\_region=830:835,1010:1015 }
\end{quote}

\end{enumerate}


\newpage

\chapter{What Gets Minimized During a Fit, and How to Minimize It}

\section{Fit Statistics: \chisquare{} or Poisson Statistics}\label{sec:fit-statistics}

(See \cite{erwin15} for a more detailed discussion of the statistical
background and the effects of minimizing different fit statistics.)

\Imfit{} attempts to find the best-fitting model via a
maximum-likelihood approach. In practice, this is done by
\textit{minimizing} a maximum-likelihood statistic defined as $-2 \ln
\mathcal{L}$, where $\mathcal{L}$ is the likelihood of a given model. The rest
of this section describes the different versions of $-2 \ln \mathcal{L}$
which can be minimized to achieve the best fit. Note that this is equivalent
to a Bayesian approach which assumes constant priors on all model parameters.

By default, \Imfit{} uses a Gaussian-based maximum likelihood statistic
which is the total \chisquare{} for the model. This is defined by
computing the sum over individual pixels $i$:
\begin{equation}
-2 \ln \mathcal{L}  \; = \; \chisquare \; = \; \sum_{i = 0}^{N} w_{i} \, (I_{m, i} - I_{d, i})^2 ,
\end{equation}
where $N$ is the total number of pixels, $I_{m, i}$ and $I_{d, i}$ are the model and data intensities
for the individual pixels, and $w_{i}$ are per-pixel weights. These weights can be
supplied directly by the user in a weight map, but normally they are derived from the
dispersions $\sigma_{i}$ of the per-pixel Gaussian errors:
\begin{equation}
w_{i} \; = \; 1/\sigma_{i}^{2} .
\end{equation}

There are three possible sources for the $\sigma_{i}$ values. The
default approach is to estimate them from the data values, assuming that
the counts per pixel follow the Gaussian approximation of Poisson
statistics, so that $\sigma_{i} = \sqrt{I_{d,i}}$. An alternate method
is to use the \textit{model} values (via the \texttt{--model-errors}
flag) instead: $\sigma_{i} = \sqrt{I_{m,i}}$. Finally, the user can
supply a ``noise'' image (via the \texttt{--noise} option) which
specifies the individual $\sigma_{i}$ (or $\sigma_{i}^{2}$) values
directly.

An arguably more accurate approach -- especially in the regime of low counts per pixel,
as is often the case for, e.g., X-ray images -- is to minimize a maximum likelihood 
statistic based directly on Poisson statistics (rather than Gaussian approximation thereof). 
One way of doing this involves computing the Cash statistic $C$:
\begin{equation}
-2 \ln \mathcal{L}  \; = \; C \; = \; 2 \sum_{i = 0}^{N} w_{i} \, (I_{m, i} \, - \, I_{d, i} \ln I_{m, i}) .
\end{equation}
In this case, all weights are automatically $=1$, except for masked pixels, which are still set $= 0$.
Specifying the Cash statistic is done with the \texttt{--cashstat} command-line flag.

A drawback of the Cash statistic is that it \textit{cannot} be minimized with the
Levenberg-Marquardt algorithm, since the latter assumes that all terms in the summation are
$\ge 0$, which is usually not true for the Cash statistic.  Fortunately, there is also the 
Poisson-MLR (maximum likelihood ratio) statistic \pmlr, which includes extra terms based 
on the data values:
\begin{equation}
-2 \ln \mathcal{L}  \; = \; \mathrm{\pmlr} \; = \;  2 \sum_{i = 1}^{N} w_{i} \, 
\left( I_{m, i} - I_{d, i} \ln I_{m, i} + I_{d, i} \ln I_{d, i} - I_{d, i} \right).
\end{equation}
Since the extra terms do not depend on the
model values, they remain unchanged during the minimization and do not
affect it. However, they have the key advantage of ensuring that all
individual-pixel values are always $\ge 0$, which makes it possible to
use the Levenberg-Marquardt algorithm to minimize \pmlr. Use of \pmlr{}
is done via the \texttt{--poisson-mlr} flag (or its shortened version
\texttt{--mlr}).\footnote{\pmlr{} is actually defined as $-2 \ln
(\mathcal{L}/\mathcal{L}_{\mathrm{max}})$; see Section~4.1.3 of \cite{erwin15}.} 

(See Section~\ref{sec:noise-maps} above for more details on how the data
and model intensities, $\sigma_{i}$ values, and weights are actually
calculated, including contributions from previously-subtracted
backgrounds, A/D gain, Gaussian read noise, and combination with masks.)




\section{Minimization Options: Levenberg-Marquardt, Nelder-Mead Simplex, Differential Evolution}

The default method for \chisquare{} (or \pmlr) minimization
used by \imfit{} is the Levenberg-Marquardt algorithm, based on the
classic \textsc{minpack-1} implementation \citep{more78} with
enhancements by Craig Markwardt.\footnote{Original C version available
at \url{https://www.physics.wisc.edu/~craigm/idl/cmpfit.html}} This is
very fast and robust, and is the most extensively tested algorithm in
\imfit, but requires an initial guess for the parameter values and can
sometimes become trapped in local minima in the \chisquare{} landscape.
(In addition, it is \textit{not} appropriate if one is using the Cash
statistic $C$, since the latter can have both per-pixel and total values
$< 0$, which least-squares algorithms like Levenberg-Marquardt cannot
handle.)

An alternative algorithm, available via the \texttt{--nm} flag,  is a
version of the Nelder-Mead simplex, as implemented by the NLopt
library.\footnote{\url{https://nlopt.readthedocs.io/en/latest/}}
This is significantly slower than Levenberg-Marquardt minimization
($\sim 5$--10 times slower for fits with one or two components), but
significantly faster than Differential Evolution (below). Like the
Levenberg-Marquardt method, it requires an initial guess for the
parameter values, but is considered less likely to become trapped in
local minima in the fit-statistic landscape. Unlike the L-M algorithm,
it can be used for minimizing $C$ (as well as \chisquare{} and
\pmlr). If you compile \imfit{} from source and want to use
this algorithm, you need to have the NLopt library installed on your
system.

The second alternate algorithm is available via the \texttt{--de} flag.
This minimizes the fit-statistic using Differential Evolution (DE)
\citep{de}, a genetic-algorithms
approach.\footnote{\url{http://www.icsi.berkeley.edu/~storn/code.html}}
It has the drawback of being $\sim$ an order of magnitude slower than
the Nelder-Mead simplex method, and \textit{much} slower ($\sim$ two
orders of magnitude) than Levenberg-Marquardt minimization. For example,
fitting a single S\'ersic function to the $256 \times 256$ image in the
\texttt{examples/} subdirectory takes $\sim 60$ times as long when using
Differential Evolution as it does when using L-M minimization. It does
has the advantage of being the least likely (at least in principle) of
being trapped in local minima in the fit-statistic landscape; it also
does \textit{not} require or use initial guesses for the parameter values.

The Differential Evolution algorithm does, however, \textit{require}
lower and upper limits for \textit{all} parameters in the configuration
file (see Section~\ref{sec:param-limits}); this is because DE generates
initial parameter-value ``genomes'' by random uniform sampling from within the
ranges specified by the parameter limits. The format of the
configuration file still requires that initial-guess values be present
for all parameters as well, but these are actually ignored by the DE
algorithm. (This is to ensure that the same configuration file can be
used with all minimization routines.)

The standard implementation of Differential Evolution uses simple
uniform sampling to generate the initial guesses: the initial value for
a given parameter in a given ``genome'' is generated by uniformly
sampling from within that parameter's limits. In some cases, this might
leave the full parameter space unevenly sampled, which \textit{might}
make it harder to find the global fit-statistic minimum if there are
multiple local minima. As an alternative, you can use the
\texttt{--de-lhs} option, which tells \imfit{} to use Latin hypercube
sampling when generating the initial parameter guesses. In practice,
it's not clear this improves the convergence speed of typical DE fits,
but it might be useful in some cases (ideally, one should probably run
experiments to see if it makes things better or worse).

(An additional set of minimization algorithms -- all of the ``local
derivative-free'' algorithms in the NLopt
library\footnote{\url{https://nlopt.readthedocs.io/en/latest/NLopt_Algorithms/}} -- can be invoked
with the \texttt{--nlopt} option. Most if not all of these seem to be
slower and/or less robust than the Nelder-Mead simplex algorithm (which
is in fact one of these NLopt algorithms) for image-fitting purposes, so
they are probably not worth using. Nonetheless, it's possible that some
image-fitting scenarios might benefit from one of these algorithms. See
Section~\ref{sec:imfit-flags} for details on the use of the
\texttt{--nlopt} option.)

\medskip

TBD. [more details of DE implementation]
% e.g., we use stRandToBest1Exp strategy, with F = 0.85 and CR = 1.0


\medskip

Note that the N-M simplex and DE algorithms do \textit{not} produce
uncertainty estimates for the best-fitting parameter values, in contrast
to the Levenberg-Marquardt approach. However, the L-M error estimates
are themselves only reliable if the minimum in the \chisquare{}
landscape is symmetric and parabolic, and if the errors for the input
image are truly Gaussian and well-determined.  See
Sections~\ref{sec:bootstrap} and \ref{sec:mcmc} for an alternative way of estimating the
parameter uncertainties.

\medskip

The fact that the minimization algorithms are relatively decoupled from the rest
of the code means that future versions of \imfit{} could include
other minimization techniques, or that ambitious users can add such techniques
themselves.


\section{Controlling the Tolerance for Minimization}

All three minimization algorithms have stop conditions based on
fractional changes in the fit-statistic (\chisquare{}, $C$, or \pmlr)
value: if further iterations do not improve the current value by more
than FTOL $\times$ the fit statistic, then the algorithm declares success and
terminates. (In the case of DE, the test condition is actually no
further improvement after 30 generations.) The default value of FTOL is
$10^{-8}$, which seems to do a reasonable job for typical images (in
fact, it's probably overkill). If you want to experiment with different
values of FTOL, you can do this via the command-line option
\texttt{--ftol}.

There are also built-in stopping conditions based on a maximum number of
iterations for the L-M algorithm (1000), a maximum number of generations for DE
(600), or a maximum number of function evaluations (i.e., computations of model
images) for the Nelder-Mead simplex algorithm (10000 times the number of free
parameters).

%TBD: info about extra stopping conditions for the L-M and N-M simplex algorithms
% [taken care of now?]




\newpage

\chapter{Outputs}

\section{Main Outputs}

\subsection{Outputs Prior to the Fit}

By default, \imfit{} prints a set of running comments to the command
line as it processes the input parameters. This includes file names,
command-line options, and general values from the config file (e.g,
image gain). This is potentially useful for debugging failed fits: e.g.,
check the output to make sure the correct image file was specified, that
any mask file was recognized (and its pixel values treated
appropriately), etc.

As part of this setup phase, \imfit{} will make an estimate of the total
memory needed for the fit (including the intermediate arrays used by the
fast Fourier transforms if PSF convolution is being done, etc.). This
should be treated as an order-of-magnitude estimate (and in fact the
actually memory used will be slightly larger than the estimate), but is
useful to catch cases where a proposed fit might run up against the
memory limits of your computer. An extra warning message will be printed
if the estimated memory use is $> 1$ GB, though \imfit{} will still go
ahead and attempt the fit. (If the memory use really is too large for
the computer, the program will probably be killed by the operating
system, which may or may not print anything useful about \textit{why}
the program was killed.)


\subsection{Outputs from the Fit}

Assuming that the fitting process converges, \imfit{} will print a
summary of the results, including the final, best-fitting parameter
values. The output parameter list is in the same format as the
configuration file, except that if the L-M algorithm is used, its error
estimates are listed after each parameter value.\footnote{No in-line
error estimates are produced if the Nelder-Mead simplex or Differential
Evolution algorithms were used for the minimization.} These error
estimates are separated from the parameter values by ``\#''; this means
that you can copy and paste the parameter list into a text file and use
that file as an input configuration file for \imfitprog, \imfitmcmc, or
\makeimage, since those programs will treat everything after ``\#'' on a
line in the configuration file as a comment. 

The best-fitting parameters will also be written to an output text file
(the default name for this is \texttt{bestfit\_parameters\_imfit.dat};
use \texttt{--save-params} to specify a different name). The output file
will also include a copy of the original command used to start \imfit{}
and the date and time it was generated; these are commented out so that
the file can be subsequently used as an \imfit{} or \makeimage{}
configuration file without modification.

The final value of the fit statistic is also printed; if the fit
statistic was \chisquare{} or PMLR, then the ``reduced'' $\chi^{2}$ or
PMLR (which accounts for the total number of unmasked pixels and
non-fixed parameter values)\footnote{The reduced values should be
interpreted with caution; it is valid in absolute terms only if the
noise has been correctly estimated \textit{and} if all differences
between the model and the data are solely due to noise, which is rarely
true for galaxies and other astronomical objects.} is also printed.
Finally, two alternate measures of the fit are also printed: the Akaike
Information Criterion (\textsc{aic}) and the Bayesian Information
Criterion (\textsc{bic}). These two are, in principle, useful for
comparing different models fit to the same data. They are defined in the
usual sense (for \textsc{aic}, \imfit{} uses the ``corrected'' version,
which accounts for cases of few data points):
\begin{eqnarray}
\mathrm{AIC} & = & -2 \ln \mathcal{L} \, +\,  2k \, + \, \frac{2k(k + 1)}{n - k - 1} \\
\mathrm{BIC} & = & -2 \ln \mathcal{L} \, + \, k \ln n ,
\end{eqnarray}
where $\mathcal{L}$ is the likelihood of the best-fit model, $k$ is the
number of free parameters, and $n$ is the number of data points (i.e.,
unmasked pixels). The value of $-2 \ln \mathcal{L}$ is equal to the
best-fit value of the chosen fit statistic: e.g., $-2 \ln \mathcal{L} =
\chisquare$ for fits that minimize \chisquare{}, and = PMLR for fits
using that statistic.

A short summary of the results of the fitting process -- minimization
algorithm and its final status, fit-statistic value, etc. -- is also
included in the output text file; these lines (like the ones listing
the original command line and the timestamp) are commented out.

By default, no model or residual (image $-$ model) images are saved, but
the command-line options \texttt{--save-model} and
\texttt{--save-residual} can be used to specify output names for those
images, and corresponding \textsc{fits} files will be saved to disk.



\section{Uncertainties on Parameter Values: L-M Estimates vs.\ Bootstrap Resampling}
\label{sec:bootstrap}

The (default) Levenberg-Marquardt minimization algorithm used by
\imfit{} automatically generates a set of (symmetric) uncertainty
estimates for each free parameter at the conclusion of the fitting
process; as noted above, these are printed to the terminal as part of
the summary output.

These values come from the covariance matrix derived from the final
Hessian matrix corresponding to the best-fit solution, and should be
viewed with caution: for example, they assume that the \chisquare{}
landscape in the vicinity of the best-fit solution is parabolic. In
practice, they should probably be seen as \textit{lower limits} on the
uncertainty.

The other fitting algorithms used by \imfit{} do not compute gradients
in the fit landscape, and so they do not produce automatic uncertainty
estimates. Although one could certainly take the solution of a
\chisquare{} or \pmlr{} fit done with the N-M simplex or DE algorithms
and use it as input to a L-M run of \imfit, thus generating L-M--based
uncertainties, this is not possible when using the Cash statistic $C$.

As an alternative to the L-M uncertainty estimates, \imfit{} offers the
option of bootstrap resampling. This is done with the
``\texttt{--bootstrap}'' command-line option, which takes the
\textit{number} of iterations as its corresponding value; e.g.

\begin{verbatim} imfit someimage.fits -c config.dat [...] --bootstrap=200
\end{verbatim}

Each iteration of bootstrap resampling generates a new data image by
sampling pixel values (with replacement) from the original data image,
and then re-runs the fit to generate a new set of parameter
values.\footnote{To speed things up, the original best-fit parameters
are used as starting values for the new fit.} After $n$ iterations, the
combined set of bootstrapped parameter values can be used as a
distribution for estimating confidence intervals; \imfit{} finds and
outputs the 68.3\% confidence intervals and the standard deviation for
each parameter. While this approach may produce more plausible
uncertainties for the best-fit parameters -- and can be used with both
\chisquare{} and Cash-statistic or Poisson-MLR statistic minimization
and as an adjunct to any of the three minimization algorithms -- it
\textit{is} slow, as one is essentially repeating (a somewhat faster
version of) the fitting process $n$ times. Ideally, one should do at
least 200 iterations -- 1000 or more is preferable -- to get reasonably
consistent confidence intervals. Since this can take \textit{much}
longer than the original fitting process, it is probably not a good idea
to use bootstrap resampling when one is engaged in exploratory fitting,
but to instead postpone it until one is reasonably certain one has the
final fit. To keep things as fast as possible, \imfit{} automatically
chooses L-M minimization for the bootstrap process -- unless the
Cash statistic is being used, in which case the N-M simplex
method is used.\footnote{If \imfit{} was compiled without the NLopt
library, then the N-M simplex method is not available and \imfit{} uses
DE instead -- which will make the bootstrap estimation \textit{very}
slow.}

Using the \texttt{--save-bootstrap} command, one can provide a filename
for saving the best-fitting parameters from all the individual resampled
fits; these are written as one line per fit. This allows more detailed
analysis of the parameter distributions, including potential correlations
between parameters.

The python module \texttt{imfit.py} (in the \texttt{python} subdirectory)
contains a function (GetBootstrapOutput) which reads in a bootstrap save
file and returns a list of the parameter names and a Numpy array with
the saved bootstrap fits.

See also Section~\ref{sec:mcmc} for how to do Markov Chain Monte Carlo
analysis using \Imfit{} models.


\newpage

\chapter{Miscellaneous Notes}

\section{Memory Usage}

As noted above, \imfit{} will print an estimate of the memory needed for a fit
when it is starting up. In most cases, this will be of merely academic interest,
unless you are planning to fit very large images and/or convolve with very large PSFs.

If you want to have an idea of what the memory usage might be
\textit{before} running \imfit, you can start by estimating the memory needed (in bytes) for the
data image
\begin{equation}
N_{\mathrm{data}} = 8 \, N_{x} N_{y},
\end{equation}
where $N_{x}$ and $N_{y}$ are the image dimensions in pixels. 

In the case of no PSF convolution, the total memory (in bytes)
will be a minimum of $\sim 4 \, N_{\mathrm{data}}$. If Levenberg-Marquardt
minimization (the default) is being used, then the total memory needed
will actually be of order $(7 + n_{\mathrm{free}}) \, N_{\mathrm{data}}$, where
$n_{\mathrm{free}}$ is the number of free parameters in the model. (This is
mostly due to the Jacobian matrix and associated arrays used
internally by the L-M minimizer.) Thus, fitting a $1000 \times 1000$
pixel image using Levenberg-Marquardt minimization and a single
elliptical S\'ersic model with no fixed parameters ($n_{\mathrm{free}} = 7)$
will require $\sim 106$ MB.

If PSF convolution (using a PSF image with dimensions $N_{x,\mathrm{PSF}} \times N_{y,\mathrm{PSF}}$)
is being done, then more memory will be needed. In this case, you should also calculate the 
memory needed for the internal model image
\begin{equation}
N_{\mathrm{model}} = 8 \, N_{x,m} N_{y,m},
\end{equation}
where $N_{x,m} = N_{x} + 2 \, N_{x,\mathrm{PSF}}$ and $N_{y,m} = N_{y} + 2 \, N_{y,\mathrm{PSF}}$,
and the memory needed for the complex FFT-related arrays
\begin{equation}
N_{\mathrm{FFT}} = 16 \, N_{x,\mathrm{FFT}} N_{y,\mathrm{FFT}},
\end{equation}
where $N_{x,\mathrm{FFT}} = N_{x} + 3 \, N_{x,\mathrm{PSF}}$ and 
$N_{y,\mathrm{FFT}} = N_{y} + 3 \, N_{y,\mathrm{PSF}}$. The total memory needed will
then be (for non--L-M minimization) of order
\begin{equation}
N_{\mathrm{data}} + 3 \, N_{\mathrm{model}} + 6 \, N_{\mathrm{FFT}}
\end{equation}
or
\begin{equation}
(4 + n_{\mathrm{free}}) N_{\mathrm{data}} + 3 \, N_{\mathrm{model}} + 6 \, N_{\mathrm{FFT}}
\end{equation}
when doing L-M minimization. Using the same example as before (fitting a
$1000 \times 1000$ pixel image with a single S\'ersic model) but
including convolution with a $100 \times 100$ pixel PSF image would thus
require $\sim 270$ MB, or $\sim 195$ MB using a minimization algorithm other than L-M.
Fitting, say, a $5000 \times 5000$ pixel image using a $1000 \times
1000$ pixel PSF image would require almost 9 GB of memory!

The estimation done by \imfit{} when starting up is slightly more accurate, but these
notes should suffice to help you figure out whether you're in the general vicinity of running out
of memory with a particular fit.




\newpage

\chapter{Makeimage}

\Imfit{} has a companion program called \makeimage, which will generate model
images using the same functions (and parameter files) as \imfit. In fact (as
noted above), the output ``best-fitting parameters'' file generated by \imfit{}
can be used as input to \makeimage, as can an \imfit{} configuration file.

\Makeimage{} \textit{does} require an output image size.  This can be specified
via command-line flags (``\texttt{--ncols}'' and ``\texttt{--nrows}''), via
specifications in the configuration file (see below), or by supplying a
reference \textsc{fits} image (``\texttt{--refimage} \textit{image-filename}''); in the
latter case, the output image will have the same dimensions as the reference
image.

\Makeimage{} can also be run in a special mode to estimate the
magnitudes and fractional luminosities of different components in a
model.


\section{Using \Makeimage{}}

Basic use of \makeimage{} from the command line looks like this:
\begin{quote}
  \texttt{\$ \makeimage{} }  [options] ~ \textit{config-file}
\end{quote}
where \textit{config-file} is the name of the \imfit{}-style configuration file
which describes the model.

As for \imfit, the ``options'' are a set of command-line flags and
options (use ``\makeimage{} \texttt{-h}'' or ``\makeimage{} \texttt{--help}'' to
see the complete list). Options must be followed by an appropriate value
(e.g., a filename, an integer, a floating-point number); this can be
separated from the option by a space, or they can be connected with an
equals sign.

\bigskip

Some notable and useful command-line flags and options include:
\begin{itemize}
\item \texttt{-o, --output} \textit{filename} -- filename for the output model
image (default = ``modelimage.fits'').

\item \texttt{--refimage} \textit{filename} -- existing reference image to
use for determining output image dimensions.

\item \texttt{--ncols} \textit{N\_columns} -- number of columns in output image

\item \texttt{--nrows} \textit{N\_rows} -- number of rows in output image

\bigskip

\item \texttt{--psf} \textit{psf-image} -- specifies a \textsc{fits} image to be convolved
with the model image. (The ``oversampled PSF'' options that \imfitprog{} uses can
also be used with \makeimage.)

\bigskip

\item \texttt{--nosave} -- do \textit{not} save the model image (useful for testing
purposes, or when estimating fluxes with \makeimage)

\bigskip

\item \texttt{--timing} \textit{N} -- generates the specified model
image \textit{N} times and computes the average time taken by the computation
(no output image will be saved)

\bigskip

\item \texttt{--list-functions} -- list all the functions \makeimage{}
can use

\item \texttt{--list-parameters} -- list all the individual parameters (in correct order)
for each functions that \makeimage{} can use


\end{itemize}



\section{Configuration Files for \Makeimage{}}

The configuration file for \makeimage{} has essentially the same format as
that for \imfit; any parameter limits that might be present are ignored.

Optional general parameters like GAIN and READNOISE are ignored, but the
following optional general parameters are available:

\begin{itemize}
\item NCOLS -- number of columns for the output image (x-size)

\item NROWS -- number of rows for the output image (y-size)

\end{itemize}




\section{Generating Single-Function Output Images}

\Makeimage{} can also output individual images for each function
in the configuration file. For example, if the configuration file specifies
a model with one S\'ersic function and two exponential functions, \makeimage{}
can generate three separate \textsc{fits} files, in addition to the (standard) sum of
all three functions.  This is done with the \texttt{--output-functions} option:
\begin{quote}
  \texttt{--output-functions} ~ \textit{root-name}
\end{quote}
where \textit{root-name} is a string that all output single-function filenames will
start with. The single-function filenames will be sequentially numbered (starting
with 1) according to the order of functions in the configuration file, and the
name of each function will added to the end; the resulting filenames will have
this format:
\begin{quote}
  \textit{root-name}{N}\texttt{\_}\textit{function-name}\texttt{.fits}
\end{quote}

Using the example specified above (a model with one S\'ersic and two exponential
functions), one could execute the following command
\begin{quote}
  \texttt{\$ \makeimage} ~ \textit{config-file} ~ \texttt{--output-functions mod}
\end{quote}
and the result would be three \textsc{fits} files, named \texttt{mod1\_Sersic.fits},
\texttt{mod2\_Exponential.fits}, and \texttt{mod3\_Exponential.fits} (in addition
to \texttt{model.fits}, which is the sum of all three functions).


\section{Using \Makeimage{} to Estimate Fluxes and Magnitudes, B/T Ratios, etc.}

Given a configuration file, you can use \makeimage{} to estimate the
total fluxes and magnitudes of different model components. For some
components -- e.g., the purely elliptical versions of the Gaussian,
Exponential, and S\'{e}rsic functions -- there are analytical
expressions which could be used. But since \imfit{} and \makeimage{} are
designed to use arbitrary functions, including ones which do not have
analytical expressions for total flux, \makeimage{} estimates the flux
for each component by internally constructing a large model image for
each component function in the configuration file, with the component
centered within this image, and then summing the pixel values of that
image. The output includes a list of total and relative fluxes (i.e.,
what fraction of the total flux each component makes up) for each
component in the model image -- and their magnitudes, if a zero point is
supplied.

There are two command-line options to do this. The first prints the results
to the console; the second saves the results to an output text file.

\begin{quote}
  \texttt{\$ \makeimage{} }  \textit{config-file} ~ \texttt{--print-fluxes}
\end{quote}

\begin{quote}
  \texttt{\$ \makeimage{} }  \textit{config-file} ~ \texttt{--save-fluxes } \textit{filename}
\end{quote}

Useful command-line flags and options:
\begin{itemize}

\item \texttt{--estimation-size} \textit{N\_columns\_and\_rows} -- size of the
(square) image to construct (the default size is 5000 pixels on a side)

\item \texttt{--zero-point} \textit{value} -- zero point for converting total counts
to magnitudes:
\begin{equation}
m \; = \; Z - 2.5 \log_{10}( {\mathrm{counts}} )
\end{equation}

\end{itemize}

This enables you to compute things like bulge/total ratios -- but it's up to you
to determine which component(s) should be considered ``bulge'', ``disk'', etc.

When run in this mode, \makeimage{} will still produce an output image file --
unless you also specify the \texttt{--nosave} option.



\newpage

\chapter{Markov Chain Monte Carlos Analysis with \imfitmcmc}\label{sec:mcmc}

\Imfit{} includes a separate program for doing Markov
chain Monte Carlo (MCMC) analysis of galaxy image models: \imfitmcmc.
This uses the exact same surface-brightness models, statistical options,
and input configuration files as \imfitprog, but instead of solving for
the ``best-fitting'' model, it produces an estimate of the
posterior-probability (i.e., likelihood) distribution. Although it
certainly \textit{can} be used to ``fit'' models to data -- if the user
is willing to adopt some convention for identifying ``best-fit'' values
from the posterior distribution\footnote{E.g., using mean, median, or
mode from the marginal distribution of each parameter.} -- it is
probably more useful as a way of determining uncertainty ranges for, and
correlations between, model parameters.

The inputs for \imfitmcmc{} are the same as for \imfitprog: data image,
model configuration file, optional PSF image(s), statistical model
(\chisquare{} based on data, model, or input error map; Poisson MLR
statistic), etc. The outputs are different: instead of a best-fitting
parameter file and optional outputs such as best-fit model image,
\imfitmcmc{} saves multiple output text files, each containing one of
the Markov chains (there will be one chain, and thus one file, for each
free parameter in the model). These are meant to be analyzed
subsequently by the user; some simple Python code to help with this is
provided.

In essence, you can use the same data and configuration file to do both a
standard fit with \imfitprog{} and MCMC analysis of the model; the
latter can then be used to determine confidence intervals, look for
multiple modes in the posterior distribution, identify correlations
between parameters, etc.

It is important to bear in mind that MCMC analysis takes \textit{much}
longer than a simple fit, even a fit done using the Differential
Evolution (DE) minimizer. For example, the \texttt{examples/}
subdirectory that comes with \Imfit{} contains a $256 \times 256$-pixel
SDSS $r$-band image of the dE galaxy IC 3478 and a configuration file for a
single-S{\'e}rsic fit to this image. The basic fit (without PSF
convolution) takes approximately 115 model-image computations and about
0.3 seconds to finish\footnote{On a MacBook Pro 2012 with a 2.7 GHz
Intel i7 quad-core CPU.} using the default Levenberg-Marquardt
minimizer. Using DE, the fit takes $\sim$11,000 model-image computations
and about 20 seconds. An MCMC analysis of the same model requires
\textit{several hundred thousand} model-image computations and
approximately ten minutes to reach convergence.

The MCMC approach that \imfitmcmc{} uses is the DREAM (DiffeRential
Evolution Adaptive Metropolis) algorithm of \citet{vrugt09}, which is
based on the earlier adaptation of DE to MCMC by \citet{ter-braak06};
more details can be found in \citet{vrugt16}. The specific
implementation used by \imfitmcmc{} is based on C++ code published by
Gabriel Rosenthal.\footnote{\url{https://github.com/gaberoo/cdream}} The
algorithm uses multiple separate Markov chains (by default, a number
equal to the number of free parameters in the model) and a DE-based
scheme for generating new proposals for each chain using differences
between the current states of other (randomly chosen) chains. A version
of the Gelman-Rubin convergence diagnostic \citep{gelman-rubin} is used
to estimate when convergence is reached, by examining the most recent
50\% of each chain; the algorithm terminates after a user-specified
maximum number of generations if convergence is not achieved before then.

In simplified terms, creating a new proposal for a chain involves scaled
offsets from the current state of the chain (i.e., the set of parameter
values $x_{i}$, with $i = 1, .., N_{\textrm{params}}$), with the base
offsets $\Delta_{i}$ taken from the difference in parameter values
between the current states of two (or more) \textit{other} chains. A
random subset of the parameter values in the current state are updated,
with the remaining parameters left unchanged.\footnote{The proposal can
thus be seen as a ``crossover'' between a parameter vector with
completely new values and the current parameter vector; this is part
of the general DE algorithm.} For each parameter that is updated, the
new value $z_{i}$ is
\begin{equation}
z_{i} = x_{i} + (1 + U) \: \gamma \: \Delta_{i} + N(0,s) ,
\end{equation}
where $U$ is a uniformly sampled random number between $\pm u$ and
$N(0,s)$ is a random sample from a Gaussian with mean of 0 and
dispersion $s$. Both $u$ and $s$ can be specified by the user, though
their default values (0.01 and $10^{-6}$, respectively) are probably
good starting points. The scale parameter $\gamma$ is
\begin{equation}
\gamma = 2.38 / \sqrt{2 \delta d^{\prime}},
\end{equation}
where $\delta$ is the number of pairs used to determine the base offset
($\delta = 1$, 2, or 3; the actual value used is randomly permuted by
the algorithm) and $d^{\prime}$ is the number of parameters being
updated for the current proposal. Every five generations $\gamma$ is set
$= 1$, to encourage occasional longer jumps outside the current location
in parameter space.

The stationary posterior-probability distribution (after convergence) is
proportional to the likelihood of the data given the model, multiplied
by an assumed prior probability which is constant between the parameter
limits specified in the configuration file and zero outside those limits.

The usual caveats about ``convergence'' of MCMC chains apply: the convergence
test is not guaranteed to identify true convergence, and it is always possible
that if run long enough, the composite chain will discover new modes in the
posterior distribution. However, since most uses of MCMC for galaxy image fitting
will probably be for purposes of identifying the distribution of parameter
values in the vicinity of the overall ``best-fit'' state, it's probably not
worth worrying too much about outlying low-probability alternate modes.



\section{Using \imfitmcmc{}}

Use of \imfitmcmc{} on the command line is almost identical to use of
\imfitprog{} (Chapter~\ref{chap:using-imfit}). The main difference is
the optional use of \texttt{-o/--output} to specify the root name for
the Markov-chain output files (the program defaults to using
\texttt{mcmc\_out} as the root name if \texttt{-o} is not used), and
some extra options for tweaking the MCMC algorithm.

The following \imfitprog{} options are \textit{not} available with \imfitmcmc:
\begin{itemize}
\item Minimizer selection and control: \texttt{--nm}, \texttt{--nlopt}, \texttt{--de},
\texttt{--ftol}
\item ``Best-fit'' output: \texttt{--save-params}, \texttt{--save-model},
\texttt{--save-residual}, \texttt{--save-weights}
\item Bootstrap-related: \texttt{--boostrap}, \texttt{--save-bootstrap}
\item \texttt{--chisquare-only}, \texttt{--fitstat-only}
\end{itemize}

\subsection{Extra options for \imfitmcmc}

\begin{itemize}
\item \texttt{-o, --output} \textit{root-name} -- the root name for
output MCMC chain files. The actual output files will be named <\textit{root-name}>\texttt{.1.txt},
<\textit{root-name}>\texttt{.2.txt}, etc. The default is ``mcmc\_out''.

\item \texttt{--nchains} $N_{\textrm{chains}}$ -- specifies the number
of MCMC chains to calculate (must be at least 3). This defaults to the
number of free parameters in the model, which is the recommended value.

\item \texttt{--append} -- specifies that pre-existing MCMC chain files should be
read in and the MCMC process continued from their final states.

\item \texttt{--max-chain-length} \textit{N} -- the maximum number of
generations (with one likelihood evaluation per generation) per chain.
The program will quit if if reaches this value. The default value is
100,000 (which means the total number of likelihood evaluations -- i.e.,
model-image computations -- will be 100,000 $\times
N_{\mathrm{chains}}$).

\item \texttt{--burnin-length} \textit{N} -- the number of generations of the initial ``burn-in''
phase, where larger jumps are taken to ensure adequate exploration of the posterior
landscape. If outlier chains are subsequently discovered, burn-in will be re-entered
for the same number of generations. Default value: 5,000.

\item \texttt{--gelman-evals} \textit{N} -- Gelman-Rubin convergence
tests will be done every \textit{N} generations (after the burn-in phase
has finished). Default value: 5,000.

\item \texttt{--uniform-offset} \textit{u} -- the limit on variations in the multiplicative
scaling applied to proposed parameter offsets, such that offsets are multiplied
by uniformly sampled numbers in the interval $[1 - u, 1 + u]$. Default value: 0.01.

\item \texttt{--gaussian-offset} \textit{s} -- Gaussian $\sigma$ value for additive
variations applied to proposed parameter offsets, such that $N(0,s)$ is added to
each offset (i.e., a Gaussian with mean $= 0$ and dispersion $= s$). Default value: $10^{-6}$.

\end{itemize}



\section{Configuration Files for \imfitmcmc{}}

Configuration files for \imfitmcmc{} are identical to those for \imfit{}, with
the restriction that \textit{parameter limits must be supplied for all non-fixed
function parameters.} (This is similar to how \imfit{} works with the Differential
Evolution miminizer.)

TBD.



\section{Analysis of \imfitmcmc{} output}

The result of running \imfitmcmc{} is a set of $N_{\textrm{chains}}$
output text files, each of which contains one of the Markov chains. The
files contain one column for each of the model parameters (plus several
additional columns with diagnostics of the MCMC process: the likelihood
value for a given set of parameters, whether the chain was in the
burn-in phase, etc.), and one row for each generation in the chain.

Each individual file can be inspected to see how the MCMC process
evolved, to check for lack of convergence, etc. To get a proper
evaluation of the estimated posterior/likelihood landscape, all the
chains should be combined, excluding the burn-in phase(s). Since the
Gelman-Rubin convergence test checks the last half of each chain, you
could plausibly use the last half of all the output chains, assuming
that \imfitmcmc{} terminated because convergence was detected. For some
analyses, this may be overkill, and using the last few thousand
generations from each chain may suffice.

Some simple Python code for reading in the MCMC output is included in
the \texttt{python/} subdirectory of the distribution, in the file
\texttt{imfit.py}. (This file in turn depends on the file
\texttt{imfit\_funcs.py} and the Scipy package, but the MCMC-related
functions themselves do not, and can be extracted into a separate module
if that makes things easier.) There are two functions of interest: 
\begin{itemize}
\item \texttt{GetSingleChain}, which reads in a single output file; 
\item \texttt{MergeChains}, which reads in \textit{all} the output files and 
concatenates them into a single composite chain, with user-specified limits 
(e.g., merge only generations $n$ or later, or merge only the last $n$ generations).
\end{itemize}
Some basic examples follow.

Assuming that \imfitmcmc{} has run and produced converged output files 
named mcmc\_out.1.txt, mcmc\_out.2.txt, etc., the following Python code will read in the
first of these files (note that in version 1.4, the output chains were numbered
starting with 0 instead of with 1):
\begin{quote}
$>>>$ import imfit \\
$>>>$ columnNames, chain1 = imfit.GetSingleChain("mcmc\_out.1.txt")
\end{quote}

The result is a list of the parameter names (columnNames) and a Numpy
array (chain1) with shape $= (n_{\textrm{rows}}$, $n_{\textrm{cols}})$,
where each row is one generation from the chain. The parameter names
map to the columns in the Numpy array.

The following bit of Python code reads in the last 5,000 generations
from each chain and merges them together, returning a list and a Numpy
array with the same form as for \texttt{GetSingleChain}. It then uses
the \texttt{corner}
package\footnote{\url{https://corner.readthedocs.io/en/latest/}}
\citep{corner} to make a scatterplot matrix (a.k.a.\ ``corner plot'') of the
different parameter distributions:

\begin{quote}
$>>>$ import imfit, corner \\
$>>>$ columnNames, allchains = imfit.MergeChains("mcmc\_out", last=5000) \\
$>>>$ corner.corner(allchains, labels=columnNames)
\end{quote}






\newpage

\chapter{Rolling Your Own Functions}

\section{Basic Requirements}

A new image function should be implemented in C++ as a subclass of
the FunctionObject base class (\texttt{function\_object.h}, \texttt{function\_object.cpp}).
At a minimum, it should provide its own implementation of the following public methods,
which are defined as virtual methods in the base class:
\begin{itemize}
\item The class constructor -- in most cases the code for this can be copied from any of the
existing FunctionObject subclasses, unless some special extra initialization is needed.
\item Setup() -- this is used by the calling program to supply the current set of
function parameters (including the $(x_{0},y_{0})$ pixel values for the center) prior
to determining intensity values for individual pixels. This
is a convenient place to do any general calculations which don't depend on the
exact pixel $(x,y)$ values.
\item GetValue() -- this is used by the calling program to obtain the surface
brightness for a given pixel location $(x,y)$. In existing FunctionObject classes,
this method often calls other (private) methods to handle details of the calculation.
\item GetClassShortName() -- this is a class function which returns
the short version of the class name as a string.

\end{itemize}

The new class should also redefine the following internal class constants:
\begin{itemize}
\item \texttt{N\_PARAMS} -- the number of input parameters (\textit{excluding} the
central pixel coordinates);
\item \texttt{PARAM\_LABELS} -- a vector of string labels for the input parameters;
\item \texttt{FUNCTION\_NAME} -- a short string describing the function;
\item \texttt{className} -- a string (no spaces allowed) giving the official name
of the function, as it would be used in a configuration file.
\end{itemize}

The \texttt{add\_functions.cpp} file should then be updated by:
\begin{enumerate}
\item including the header file for the new class;
%\item adding the class short name as a string to the \texttt{FUNCTION\_NAMES} array;
%\item incrementing the \texttt{N\_FUNCTIONS} constant;
\item adding 2 lines to the PopulateFactoryMap() function to add the ability to create an instance of
the new class.
\end{enumerate}

Finally, the name of the C++ implementation file for the new class should be added
to the \texttt{SConstruct} file to ensure it gets included in the compilation; the
easiest thing is to add the file's name (without the \texttt{.cpp} suffix) to the
\texttt{functionobject\_obj\_string} multi-line string definition.

Existing examples of FunctionObject subclasses can be found in the ``\texttt{function\_objects}''
subdirectory of the source-code distribution, and are the best place to look in order
to get a better sense of how to implement new FunctionObject subclasses.


\section{A Simple Example}

To illustrate, we'll make a new version of the Moffat function (which already
exists, so this is purely for pedagogical purposes) by copying and modifying the
code for the Gaussian function.

\bigskip

We need to make three sets of changes:
\begin{itemize}
\item Change the class name from ``Gaussian'' to our new name (``NewMoffat'');
\item Change the relevant code which computes the function;
\item Rename, add, or delete variables to accommodate the new algorithm.
\end{itemize}


\subsubsection{Create and Edit the Header File}

Change directory to the directory with the \imfit{} source code, and then
to the subdirectory named ``\texttt{function\_objects}''. Copy the file
\texttt{func\_gaussian.h} and rename it to \texttt{func\_new-moffat.h}. Edit
this file and change the following lines:

\begin{verbatim}
#define CLASS_SHORT_NAME  "Gaussian"
\end{verbatim} 
(replace \texttt{"Gaussian"} with \texttt{"NewMoffat"})

\begin{verbatim}
class Gaussian : public FunctionObject
\end{verbatim}
(replace \texttt{Gaussian} with \texttt{NewMoffat})

\begin{verbatim}
    Gaussian( );
\end{verbatim}
(replace \texttt{Gaussian} with \texttt{NewMoffat})

And finally edit the list of class data members, changing this:
\begin{verbatim}
  private:
    double  x0, y0, PA, ell, I_0, sigma;   // parameters
    double  q, PA_rad, cosPA, sinPA;   // other useful (shape-related) quantities
\end{verbatim}
to this:
\begin{verbatim}
  private:
    double  x0, y0, PA, ell, I_0, fwhm, beta;   // parameters
    double  alpha;
    double  q, PA_rad, cosPA, sinPA;   // other useful (shape-related) quantities
\end{verbatim}


\subsubsection{Create and Edit the Class File}

Copy the file \texttt{func\_gaussian.cpp} and rename it to \texttt{func\_new-moffat.cpp}. 

\bigskip
\noindent \textit{Initial changes, including parameter number and names:}
\smallskip

Edit this file and change the following lines (changed text indicated in red):

\begin{quote}
\texttt{\#include "\red{func\_new-moffat.h}"} \\

const int  N\_PARAMS = \red{5}; \\

const char  PARAM\_LABELS[][20] = \{"PA", "ell", "I\_0", \red{"fwhm", "beta"}\}; \\

const char  FUNCTION\_NAME[] = "\red{Moffat} function";

\end{quote}

\bigskip
\noindent \textit{Change references to class name:}
\smallskip

Change all class references from ``Gaussian'' to ``NewMoffat'' (e.g.,
\texttt{Gaussian::Setup} becomes \texttt{NewMoffat::Setup}).

\bigskip
\noindent \textit{Changes to Setup method:}
\smallskip

In the Setup method, you need to change how the input is converted into
parameters, and do any useful pre-computations. So the initial processing of
the ``params'' input changes from this:
\begin{verbatim}
  PA = params[0 + offsetIndex];
  ell = params[1 + offsetIndex];
  I_0 = params[2 + offsetIndex];
  sigma = params[3 + offsetIndex];
\end{verbatim}

to this:
\begin{verbatim}
  PA = params[0 + offsetIndex];
  ell = params[1 + offsetIndex];
  I_0 = params[2 + offsetIndex];
  fwhm = params[3 + offsetIndex];
  beta = params[4 + offsetIndex];
\end{verbatim}
and at the end we replace this:
\begin{verbatim}
  twosigma_squared = 2.0 * sigma*sigma;
\end{verbatim}
with this:
\begin{verbatim}
  // compute alpha:
  double  exponent = pow(2.0, 1.0/beta);
  alpha = 0.5*fwhm/sqrt(exponent - 1.0);
\end{verbatim}


\bigskip
\noindent \textit{Changes to CalculateIntensity method:}
\smallskip

Although it is the public method GetValue which is called by other parts of
the program, we don't actually need to change the current version of that method
in this example. The code in the original Gaussian version of GetValue
converts pixel positions to a scaled radius value, given input values for
the center, ellipticity, and position angle, and then calls the private method
CalculateIntensity to determine the intensity as a function of the radius.
Since we're still assuming a perfectly elliptical shape, we can keep the
existing code. (GetValue also includes possible pixel subsampling, which
is useful for cases where intensity changes rapidly one scales of a single pixel;
we'll apply a simple modification for the Moffat function later on.)

So in this case we actually implement the details of the new function's algorithm in
CalculateIntensity. Replace the original version of that method with the
following:

\begin{verbatim}
double NewMoffat::CalculateIntensity( double r )
{
  double  scaledR, denominator;
  
  scaledR = r / alpha;
  denominator = pow((1.0 + scaledR*scaledR), beta);
  return (I_0 / denominator);
}
\end{verbatim}

\bigskip
\noindent \textit{Changes to CalculateSubsamples method:}
\smallskip

Although pixel subsampling is performed in the GetValues method, the
determination of whether or not to actually \textit{do} the subsampling
-- and how much of it to do -- is determined in CalcualteSubsamples.

For the Gaussian function, subsampling can be useful
happen when $r < 1$ \textit{and} $\sigma < 1$. The equivalent
for the Moffat function would be $r < 1$ and $\alpha < 1$, so
change the line in CalculateSubsamples that says
\begin{verbatim}
  if ((sigma <= 1.0) && (r <= 1.0))
\end{verbatim}
to say
\begin{verbatim}
  if ((alpha <= 1.0) && (r <= 1.0))
\end{verbatim}


\bigskip

%In this simple example, we aren't changing the isophote geometry (i.e.,
%we're still assuming a perfectly elliptical shape), so we don't need to
%change the GetValue method, which converts pixel position to a scaled
%radius value.  It probably doesn't make sense to change the
%CalculateSubsamples method, either, so we can leave that alone.

At this point, most of the work is done.  We only need to update
\texttt{add\_functions.cpp} so it knows about the new function and
update the SConstruct file so that the new function is included in the
compilation.


\subsubsection{Edit add\_functions.cpp}

We need to do two simple things here:
\begin{enumerate}
\item Include the header file for our new function. Add the following line near
the top of the file, where the other header files are included:\\
\texttt{\#include "func\_new-moffat.h"}

\item Add code to generate an instance of our new class as part of the
function-factory map. Inside the function PopulateFactoryMap, add the following lines:
\begin{verbatim}
  NewMoffat::GetClassShortName(classFuncName);
  input_factory_map[classFuncName] = new funcobj_factory<NewMoffat>();
\end{verbatim}

\end{enumerate}



\subsubsection{Edit the SConstruct File}

In the SConstruct file, locate the place where the variable
``functionobject\_obj\_string'' is defined (e.g., search for the string
"functionobject\_obj\_string ="). This variable is bound to a string containing a
compact list of all the filenames containing function-object code. Insert our
new function's name (``func\_new-moffat'') into the list.

\bigskip

That's it! You should now be able to recompile \imfit{} and \makeimage{} 
(see Section~\ref{sec:build}) to use
the new function. (Assuming there aren't any bugs in your new code\ldots.)



\section{Further Notes on Writing Your Own Functions}

TBD.

Some potentially useful auxiliary functions can be found in the file
\texttt{helper\_funcs.h} in the ``\texttt{function\_objects}'' subdirectory,
such as a function which calculates the $b_{n}$ parameter for a S\'ersic
function, and a function which calculates the effective radius for a
generalized ellipse.

%Really simple example: FlatSky
%
%GetValues vs CalculateIntensity
%
%3D functions -- see existing functions for guidance; also note helper functions
%in \texttt{helper\_funcs\_3d.h/cpp}.



\newpage

\chapter{Acknowledging Use of \Imfit}

A paper describing \imfit{} \citep{erwin15} has been published in
\textit{The Astrophysical Journal}
(\url{https://ui.adsabs.harvard.edu/abs/2015ApJ...799..226E/abstract}) and can be
found on the arXiv at \url{https://arxiv.org/abs/1408.1097}; you can also
reference the current URL
(\url{https://www.mpe.mpg.de/~erwin/code/imfit/}) and/or the Github URL
(\url{https://github.com/perwin/imfit/}) if \imfit{} has been useful in
your research.


\newpage

\appendix
\chapter{Standard Functions in Detail}\label{app:functions}

Unless otherwise noted, all ``intensity'' parameters (\texttt{I\_sky},
\texttt{I\_0}, \texttt{I\_e}, etc.) are in units of counts per pixel, and all
lengths are in pixels.

A sample function specification (giving the parameters in their proper order),
as you would use in a configuration file, is listed for each function
description.

``Elliptical'' functions are defined to have an intensity which is constant on
concentric, similar ellipses (with specified ellipticity and major-axis position angle);
the intensity profile is defined as a function of the semi-major axis $a$.


\section{2D Functions}

The main set of image functions provided create 2D intensity distributions
directly. These include most of the usual suspects used in 2D image fitting:
constant background, Gaussian, exponential, S{\'e}rsic, etc.

\medskip

\textbf{Common parameters}: 
\begin{itemize}
\item \texttt{PA} = position angle (e.g., of the major axis), measured in degrees CCW from
the image +y axis. This is equivalent to standard astronomical position angles \textit{if}
your image has standard astronomical orientation (N up, E to the left).
\item \texttt{ell} = ellipticity ($1 - b/a$, where $a$ and $b$ are semi-major and semi-minor
axes of the ellipse, respectively).
\end{itemize}


\subsubsection{FlatSky}

A uniform background: $I(x,y) = I_{\mathrm{sky}}$ everywhere.

\begin{verbatim}
FUNCTION FlatSky
I_sky
\end{verbatim}


\subsubsection{TiltedSkyPlane}

A background in the form of an inclined plane: $I(x,y) = I_0$ at the center
(X0,Y0), with $x$ and $y$ slopes given by $m_x$ and $m_y$.
\begin{equation}
I(x,y) \, = \, I_{0} + m_{x} (x - X_{0}) + m_{y} (y - Y_{0}).
\end{equation}

\begin{verbatim}
FUNCTION TiltedSkyPlane
I_0
m_x
m_y
\end{verbatim}


\subsubsection{Gaussian}

This is an elliptical 2D Gaussian function, with the major-axis intensity
profile given by
\begin{equation}
I(a) \, = \, I_{0} \exp(-a^2/(2 \sigma^2)).
\end{equation}

\begin{verbatim}
FUNCTION Gaussian
PA
ell
I_0
sigma
\end{verbatim}


\subsubsection{Moffat}

This is an elliptical 2D \citet{moffat69} function, with the major-axis intensity profile
given by
\begin{equation}
I(a) \, = \, \frac{I_{0}  }{(1 + (a/\alpha)^{2})^{\beta} },
\end{equation}
where $\alpha$ is defined as
\begin{equation}
\alpha \, = \, \frac{ {\mathrm{FWHM}}}{2 \sqrt{2^{1/\beta} - 1}}.
\end{equation}
In practice, FWHM describes the overall width of the profile, while $\beta$ describes that
strength of the wings: lower values of $\beta$ mean more intensity in the wings
than is the case for a Gaussian (as $\beta \rightarrow \infty$, the Moffat profile
approaches a Gaussian).

The Moffat function is often a good approximation to typical telescope PSFs (see, e.g.,
\citealt{trujillo01}), and \makeimage{} can easily be used to generate Moffat PSF images.

\begin{verbatim}
FUNCTION Moffat
PA
ell
I_0
fwhm
beta
\end{verbatim}


%  double  exponent = pow(2.0, 1.0/beta);
%  alpha = 0.5*fwhm/sqrt(exponent - 1.0);
%  q = 1.0 - ell;
%
%  scaledR = r / alpha;
%  denominator = pow((1.0 + scaledR*scaledR), beta);
%  return (I_0 / denominator);


\subsubsection{PointSource}

This function approximates a point source (e.g., star, AGN, etc.) by
taking the user-input PSF image and generating an interpolated,
intensity-scaled copy of it at the X0,Y0 position of the parent function
set. It has only one free parameter: $I_{\mathrm{tot}}$, which is the
factor that the PSF image is multiplied by, and which will usually
correspond to the total flux of the point source. Of course, it also
\textit{requires} that a PSF image be supplied!

For standard model-image generation, the main user-supplied PSF image is
used. If PSF ovsersampling is specified, then any PointSource objects
which fall within an oversampling region (specified via
\texttt{--overpsf\_region}) will interpolate the corresponding
\textit{oversampled} PSF image (specified via \texttt{--overpsf}) instead.

The interpolation is done using the 2D bicubic function
(\texttt{gsl\_interp2d\_bicubic}) from the GNU Scientific Library.

\begin{verbatim}
FUNCTION PointSource
I_tot
\end{verbatim}


\subsubsection{ModifiedKing}

This is an elliptical 2D function with the intensity profile given by a 
``modified King'' function \citep{elson99,peng10}, which is a generalization
of the original King profile \citep{king62}:
\begin{equation}
I(a) \, = \, I_{0} \left[1 - \frac{1}{(1 + (r_{t}/r_{c})^{2})^{1/\alpha}} \right]^{-\alpha}
  \times \: \left[ \frac{1}{(1 + (r/r_{c})^{2})^{1/\alpha}} - 
  \frac{1}{(1 + (r_{t}/r_{c})^{2})^{1/\alpha}} \right]^{\alpha},
\end{equation}
where $I_{0}$ is the central intensiy, $r_{c}$ is the ``core'' radius,
and $r_{t}$ is the ``tidal'' or ``truncation'' radius (outside of which
the intensity is 0).
This reduces to the original King profile when $\alpha = 2$.

\begin{verbatim}
FUNCTION ModifiedKing
PA
ell
I_0
r_c
r_t
alpha
\end{verbatim}


\subsubsection{ModifiedKing2}

This is an alternate interface for the ModifiedKing profile. It produces
exactly the same surface-brightness model, but uses the
``concentration'' $c = r_t/r_c$ as a free parameter (in place of the
tidal/truncation radius $r_{t}$, which can be recovered as $r_{t} = c r_{c}$).

\begin{verbatim}
FUNCTION ModifiedKing2
PA
ell
I_0
r_c
c
alpha
\end{verbatim}




\subsubsection{Exponential}

This is an elliptical 2D exponential function, with the major-axis intensity
profile given by
\begin{equation}
I(a) \, = \, I_{0} \exp(-a/h),
\end{equation}
where $I_{0}$ is the central surface brightness and $h$ is the scale length.

\begin{verbatim}
FUNCTION Exponential
PA
ell
I_0
h
\end{verbatim}


\subsubsection{Exponential\_GenEllipse}

Similar to the Exponential function, but using generalized ellipses (``boxy'' to
``disky'' shapes) instead of pure ellipses for the isophote shapes.  Following
\citet{athanassoula90}, the shape of the elliptical isophotes is controlled by
the \texttt{c0} parameter, such that a generalized ellipse with ellipticity $= 1
- b/a$ is described by
\begin{equation}
\left( \frac{|x|}{a} \right)^{c_{0} + 2} \! \! + \; \left( \frac{|y|}{b} \right)^{c_{0} + 2}  = \; 1,
\end{equation}
where $|x|$ and $|y|$ are distances from the ellipse center in the coordinate system
aligned with the ellipse major axis ($c_{0}$ corresponds to $c - 2$ in the original
formulation of Athanassoula et al).
Thus, values of $c_{0} < 0$ correspond to disky isophotes, while values $> 0$ describe boxy
isophotes; $c_{0} = 0$ corresponds to a perfect ellipse.

\begin{verbatim}
FUNCTION Exponential_GenEllipse
PA
ell
c0
I_0
h
\end{verbatim}


\subsubsection{Sersic}

This is an elliptical 2D S\'ersic function with the major-axis intensity
profile given by
\begin{equation}
I(a) \; = \; I_{e} \: \exp \left\{ -b_{n} \left[ \left( \frac{a}{r_{e}} \right)^{1/n} \! - \: 1 \right] \right\},
\end{equation}
where $I_{e}$ is the surface brightness at the effective (half-light) radius $r_{e}$
and $n$ is the S\'ersic index controlling the shape of the intensity profile. The
value of $b_{n}$ is formally given by the solution to the transcendental equation
\begin{equation}
\Gamma(2 n) \; = \; 2 \gamma(2n, b_{n}),
\end{equation}
where $\Gamma(a)$ is the gamma function and $\gamma(a, x)$ is the incomplete gamma function.
However, in the current implementation $b_{n}$ is calculated via the polynomial approximation
of \citet{ciotti99} when $n > 0.36$ and the approximation of \citet{macarthur03} when
$n \leq 0.36$.

Note that the S\'ersic function is equivalent to the de Vaucouleurs ``$r^{1/4}$'' profile
when $n = 4$, to an exponential when $n = 1$, and to a Gaussian when $n = 0.5$.

\begin{verbatim}
FUNCTION Sersic
PA
ell
n
I_e
r_e
\end{verbatim}


\subsubsection{Sersic\_GenEllipse}

Similar to the Sersic function, but using generalized ellipses (``boxy'' to
``disky'' shapes) instead of pure ellipses for the isophote shapes.  See the
discussion of the \texttt{Exponential\_GenEllipse} function above for details of the isophote
shapes.

\begin{verbatim}
FUNCTION Sersic_GenEllipse
PA
ell
c0
n
I_e
r_e
\end{verbatim}



\subsubsection{Core-Sersic}

This generates an elliptical 2D function with the major-axis intensity profile
given by the Core-S{\'e}rsic model \citep{graham03,trujillo04}. This has a
S\'ersic profile (parameterized by $n$ and $r_{e}$) for radii $>$ the break
radius $r_{b}$ and a single power law with index $-\gamma$ for radii $< r_{b}$.
The transition between the two regimes is mediated by the parameter $\alpha$:
for low values of $\alpha$, the transition is very gradual and smooth, while for
high values of $\alpha$ the transition becomes very abrupt (a perfectly sharp
transition can be approximated by setting $\alpha =$
some large number, such as 100). The overall intensity scaling is set by $I_{b}$,
the intensity at the break radius $r_{b}$.

\begin{verbatim}
FUNCTION Core-Sersic
PA
ell
n
I_b
r_e
r_b
alpha
gamma
\end{verbatim}



%\subsubsection{FlatExponential} 
%
%Similar to Exponential, but with an inner radial zone ($a < r_{\rm break}$)
%of constant surface brightness $I_{0}$.
%
%\begin{verbatim}
%FUNCTION FlatExponential
%PA
%ell
%I_0
%h
%r_break
%alpha
%\end{verbatim}


\subsubsection{BrokenExponential}\label{sec:brokenexp}

Similar to Exponential, but with \textit{two}
exponential radial zones (with different scalelengths) joined by a transition region
at $R_{b}$ of variable sharpness:
\begin{equation}
	I(a) \; = \; S \, I_{0} \, e^{-\frac{a}{h_{1}}} [1 + e^{\alpha(a \, - \,
	R_{b})}]^{\frac{1}{\alpha} (\frac{1}{h_{1}} \, - \, \frac{1}{h_{2}})},
\end{equation}
where $I_{0}$ is the central intensity of the inner exponential, $h_{1}$ and
$h_{2}$ are the inner and outer exponential scale lengths, $R_{b}$ is the break radius, and
$\alpha$ parameterizes the sharpness of the break.  (See \citet{erwin08}.) Low values of $\alpha$
mean very smooth, gradual breaks, while high values correspond to abrupt
transitions.  $S$ is a scaling factor, given by
\begin{equation}
  S \; = \; (1 + e^{-\alpha R_{b}})^{-\frac{1}{\alpha} (\frac{1}{h_{1}} \, - 
  \, \frac{1}{h_{2}})}.
\end{equation}

Note that the parameter $\alpha$ has units of length$^{-1}$ (i.e., pixels$^{-1}$).

\begin{verbatim}
FUNCTION BrokenExponential
PA
ell
I_0
h1
h2
r_break
alpha
\end{verbatim}


\subsubsection{GaussianRing}

An elliptical ring with a radial profile consisting of a Gaussian
centered at $r = R_{\mathrm{ring}}$.

\begin{verbatim}
FUNCTION GaussianRing
PA
ell
A
R_ring
sigma_r
\end{verbatim}


\subsubsection{GaussianRing2Side}

Similar to GaussianRing, but now using an asymmetric Gaussian (different
values of $\sigma$ for $r < R_{\mathrm{ring}}$ and $r > R_{\mathrm{ring}}$).

\begin{verbatim}
FUNCTION GaussianRingAz
PA
ell
A_maj
A_min_rel
R_ring
sigma_r
\end{verbatim}


\subsubsection{GaussianRingAz}

TBD. 

Similar to GaussianRing, except that the peak radial intensity is modulated
by a cosine function, varying from $A_{\mathrm{maj}}$ along the ellipse major
axis to $A_{\mathrm{min}} = A_{\mathrm{min\_rel}} A_{\mathrm{maj}}$.

\begin{verbatim}
FUNCTION GaussianRingAz
PA
ell
A_maj
A_min_rel
R_ring
sigma_r
\end{verbatim}


\subsubsection{EdgeOnDisk}

This function provides the analytical form for a perfectly edge-on disk with a
radial exponential profile, using the Bessel-function solution of \citet{vdk81}
for the radial profile and the generalized sech function of \citet{vdk88} for
the vertical profile.\footnote{This model was used by \citet{yoachim06} for 2D
modeling of thin and thick disks in edge-on galaxies, though typically with $n$
fixed to values of 1 or 2.} The position angle parameter (PA) describes the
angle of the disk major axis; there is no ellipticity parameter.

In a coordinate system aligned with the edge-on disk, $r$ is the distance from the minor
axis (parallel to the major axis) and $z$ is the perpendicular direction, with $z = 0$
on the major axis. (The latter corresponds to height $z$ from the galaxy midplane.) The 
intensity at $(r,z)$ is given by
\begin{equation}
I(r,z) \; = \; \mu(0,0) \; (r/h) \; K_{1}(r/h) \;\, {\mathrm{sech}}^{2/n} (n \, z/(2 \, z_{0}))
\end{equation}
where $h$ is the exponential scale length in the disk plane, $z_{0}$ is the vertical
scale height, and $K_{1}$ is the modified Bessel function. The central surface brightness 
$\mu(0,0)$ is given by
\begin{equation}
\mu(0,0) \; = \;  2 \, h \, L_{0},
\end{equation}
where $L_{0}$ is the central luminosity \textit{density} (see \citealt{vdk81}). Note that 
$L_{0}$ is the actual parameter required by the function; $\mu(0,0)$ is calculated 
internally.

When $n = 1$, this becomes the familiar $\mathrm{sech}^2$ model for the
vertical distribution of a disk (with $z_{0}$ corresponding to $1/2$ of the
$z_0$ in the original definition of \citet{vdk81}). As $n \rightarrow \infty$,
the vertical distribution approaches an exponential with $\exp(-z/z_{0})$. In practice,
the code substitutes a pure exponential function for the $\mathrm{sech}^{2/n}$ term whenever 
\begin{equation}
\frac{n}{2} \frac{z}{z_{0}} > 100.
\end{equation}

\begin{verbatim}
FUNCTION EdgeOnDisk
PA
L_0
h
n
z_0
\end{verbatim}


\subsubsection{EdgeOnRing}

A simplistic model for an edge-on ring, using two offset components located
at distance $\pm$\texttt{r} from the center of the function set. Each component
(i.e., each side of the ring) is a symmetric Gaussian with size
\texttt{sigma\_r} for the radial profile and a symmetric Gaussian with
size \texttt{sigma\_z} for the vertical profile. (See GaussianRing3D for a similar
component which does line-of-sight integration through a 3D luminosity-density
model of a ring.)

\begin{verbatim}
FUNCTION EdgeOnRing
PA
I_0
r
sigma_r
sigma_z
\end{verbatim}


\subsubsection{EdgeOnRing2Side}

Similar to EdgeOnRing, but now the radial profile for the two components is
asymmetric: the inner ($|R| < R_{\mathrm{ring}}$) side of each component is a Gaussian
with radial size \texttt{sigma\_r\_in}, while the outer side has radial size
\texttt{sigma\_r\_out}.

\begin{verbatim}
FUNCTION EdgeOnRing2Side
PA
I_0
r
sigma_r_in
sigma_r_out
sigma_z
\end{verbatim}


\subsubsection{FerrersBar2D}

This produces a 2D analog of the classic \citet{ferrers} ellipsoid (see
FerrersBar3D in Section~\ref{sec:ferrersbar3d} for the original 3D
version), where the intensity is constant on (generalized) ellipses,
with the intensity going to zero outside a specified semi-major axis ($=
a_{\mathrm{bar}}$ along the major axis).

The surface-brightness function is
\begin{equation}\label{eqn:ferrers2d}
 I(m) = 
  \begin{cases} 
   \: I_0 \, (1 - m^{2})^{n} & \text{if } m < 1 \\
   \: 0                      & \text{otherwise}
  \end{cases}
\end{equation}
where $m$ is the elliptical radius, defined (assuming ellipticity $= 1
- b/a$) by:
\begin{equation}
m^{2} =  \left( \frac{|x|}{a} \right)^{c_{0} + 2} \! \! + \; \left( \frac{|y|}{b} \right)^{c_{0} + 2} .
\end{equation}

%\left( \frac{|x|}{a} \right)^{c_{0} + 2} \! \! + \; \left( \frac{|y|}{b} \right)^{c_{0} + 2}  = \; 1,

This is inspired by functions used in 2D decompositions by \citet{laurikainen05}
and \citet{aguerri09}. It is similar to the ``Ferrer'' component in
GALFIT, except that it lacks the latter's ``central slope'' parameter $\beta$.

\begin{verbatim}
FUNCTION FerrersBar2D
PA
ell
c0
I_0
n
a_bar
\end{verbatim}
%const char  PARAM_LABELS[][20] = {"PA", "ell", "c0", "n", "I_0", "a_bar"};


\subsubsection{FlatBar}

TBD.

see \cite{erwin20}, especially Appendix~A.

\begin{verbatim}
FUNCTION FlatBar
PA
ell
deltaPA_max
I_0
h1
h2
r_break
alpha
\end{verbatim}





\section{3D Functions}

The following are image functions which use line-of-sight
integration through a 3D luminosity-density model to create a projected 2D
image.

The functions are defined so as to have a primary plane (e.g., the
equatorial plane for a disk galaxy); the orientation of this plane is
defined by the \texttt{PA} and \texttt{inc} parameters, which specify
the angle of the line of nodes (in degrees CCW with respect to the image
+y axis) and the inclination to the line of sight (also in degrees),
respectively. Thus, \texttt{PA} $= 0$ will align the line of nodes
vertically, while \texttt{PA} $= 90$ will make it horizontal (parallel
to the image x-axis).\footnote{The goal is to ensure that the
orientation of the component's line of nodes follows the same
conventions as for the 2D functions, so that an inclined
ExponentialDisk3D function with PA $= 30$ will have the same orientation
as an elliptical 2D Exponential function with PA $= 30$.} The
inclination is defined in the usual astronomical sense: $i = 0$ for a
face-on system and $i = 90$ for an edge-on system. See Section~6.2 of
\citet{erwin15} for details of how the line-of-sight integration is
handled.

For the GaussianRing3D and FerrersBar3D functions, which are not
axisymmetric, there is an additional ``position angle'' parameter
(\texttt{PA\_ring} or \texttt{PA\_bar}), which defines the position of
the ring's or bar's major axis \textit{in the primary plane} (i.e., prior to any
projection) with respect to the primary plane's +x axis. (The logic
behind this is that when the primary plane's line of nodes is
\textit{horizontal} -- i.e., PA $= 90$ -- the orientation of the
ring's major axis follows the usual orientation conventions with respect
to the image +y axis. You are, of course, free to change this if you
write 3D components of your own, though I will probably continue to
follow it in the future.)


\subsubsection{ExponentialDisk3D}

This function implements a 3D luminosity density model for an
axisymmetric disk with an exponential radial profile and a
${\mathrm{sech}}^{2/n}$ vertical profile (as for the EdgeOnDisk
function), using line-of-sight integration to create the projected
surface-brightness profile for arbitrary inclinations.

In a cylindrical coordinate system $(r, z)$ aligned with the disk (where the disk
midplane has $z = 0$), the luminosity density at radius $r$ from 
the central axis and
at height $z$ from the midplane is given by
\begin{equation}
j(r,z) \; = \; J_{0} \; \exp(-r/h) \; {\mathrm{sech}}^{2/n} (n \, z/(2 \, z_{0}))
\end{equation}
where $h$ is the exponential scale length in the disk plane, $z_{0}$ is the vertical
scale height, and $J_{0}$ is the central luminosity density.

When $n = 1$, the vertical distribution is the familiar $\mathrm{sech}^2$ model
(with $z_{0}$ corresponding to $1/2$ of the $z_0$ in the original definition of
\citet{vdk81}). As $n \rightarrow \infty$, the vertical distribution approaches
an exponential with $\exp(-z/z_{0})$; in practice, the can be approximated by
setting $n$ equal to some fixed, large number.


\begin{verbatim}
FUNCTION ExponentialDisk3D
PA
inc
J_0
h
n
z_0
\end{verbatim}

Because this function performs numerical integration for each pixel value, it will be
slower than the analytic EdgeOnDisk function (though the latter is correct only in
the $i= 90\arcdeg$ case), and even slower than the standard Exponential function.



\subsubsection{BrokenExponentialDisk3D}

This function is identical to the ExponentialDisk3D function, except
that the radial profile of the luminosity density follows a
broken-exponential function (e.g., Section~\ref{sec:brokenexp}) instead
of a simple exponential. Consequently, it has the following parameters:

\begin{verbatim}
FUNCTION BrokenExponentialDisk3D
PA
inc
J_0
h1
h2
r_break
alpha
n
z_0
\end{verbatim}




\subsubsection{GaussianRing3D}

This function does line-of-sight integration through an elliptical ring.
The ring is defined as having luminosity density with a radial Gaussian
profile (centered at \texttt{a\_ring} along ring's major axis, with
in-plane width $\sigma$) and a vertical exponential profile (with scale
height \texttt{h\_z}). The ring can be envisioned as residing in an
(invisible) plane which has a line of nodes at angle \texttt{PA} and
inclination \texttt{inc} (as for the ExponentialDisk3D function, above);
within this plane, the ring's major axis is at position angle
\texttt{PA\_ring} \textit{relative to the perpendicular to the line of
nodes}, and the ring has an ellipticity given by \texttt{ell}.

\begin{verbatim}
FUNCTION GaussianRing3D
PA
inc
PA_ring
ell
J_0
a_ring
sigma
h_z
\end{verbatim}






\subsubsection{FerrersBar3D}\label{sec:ferrersbar3d}

This function does line-of-sight integration through a \citet{ferrers}
ellipsoid, where the luminosity density is constant on concentric,
stratified ellipsoidal shells, with the density going to zero outside a
specified ellipsoidal radius ($= R_{\mathrm{bar}}$ along the major
axis). The potential corresponding to the mass-density version of this
function has commonly been used to represent galactic bars in
theoretical studies of orbits in barred galaxies.

As with the GaussianRing3D component, the ellipsoid can be imagined as
lying in an (invisible) ``equatorial'' plane -- defined by the first two
axes of the ellipsoid -- with a line of nodes at angle \texttt{PA} and
inclination \texttt{inc} (as for the ExponentialDisk3D function, above);
within this plane, the ellipsoid's major axis is at position angle
\texttt{barPA} \textit{relative to the perpendicular to the line of
nodes} (i.e., at $90 + $\texttt{barPA} degrees relative to the line of
nodes). The shape of the ellipsoid is defined by the axis ratios $q =
b/a$ and $q_{z} = c/a$, where $a$ ($= R_{\mathrm{bar}}$) and $b$ are the
semi-major and semi-minor axes in the equatorial plane and $c$ is in the
direction perpendicular to the equatorial plane. For simplicity, it is
assumed that $q \leq 1$ and $q_{z} \leq 1$; however, it is not required
that $q_{z}$ must be $\leq q$.

The luminosity density function is
\begin{equation}\label{eqn:ferrers}
 j(m) = 
  \begin{cases} 
   \: J_0 \, (1 - m^{2})^{n} & \text{if } m < 1 \\
   \: 0                      & \text{otherwise}
  \end{cases}
\end{equation}
where $m$ is the ellipsoidal radius:
\begin{equation}
m^2 =  \frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} ,
\end{equation}
with $a = \rbar$, $b = q \rbar$, and $c = q_{z} \rbar$. Typical values of $n$
used in theoretical studies are 1 and 2.

Note that this is related to but different from the ``Ferrer'' component
in GALFIT, which defines a 2D surface-brightness function using Eqn.~\ref{eqn:ferrers}.

\begin{verbatim}
FUNCTION FerrersBar3D
PA
inc
barPA
J_0
R_bar
q
q_z
n
\end{verbatim}




\chapter{Acknowledgments}

Major inspirations for \Imfit{} include both \textsc{galfit} \citep{peng02,peng10} and 
\textsc{budda} \citep{desouza04,gadotti08}.

Thanks also to Michael Opitsch and Michael Williams for being (partly
unwitting) beta testers and for their feedback, to Martin Kuemmel for
suggesting an early improvement (and finding a related bug), to Roberto
Saglia for urging me to implement the Core-S{\'e}rsic function, and to
Maximilian Fabricius for suggesting improvements to the documentation.
Additional bug reports and suggestions from Andr{\'e} Luiz de Amorim,
Giulia Savorgnan, David Streich, Guillermo Barro, Sergio Pascual, Lee
Kelvin, Colleen Gilhuly, Semyeong Oh, Benne Holwerde, David Wilman, 
Iskren Georgiev, and Corentin Schreiber are gratefully appreciated.


\section{Data Sources}

Sample \textsc{fits} images for demonstration and testing use are taken
from Data Release 7 \citep{abazajian09} of the Sloan Digital Sky Survey
\citep{york00}. Funding for the creation and distribution of the Sloan
Digital Sky Survey Archive has been provided by the Alfred P. Sloan
Foundation, the Participating Institutions, the National Aeronautics and
Space Administration, the National Science Foundation, the U.S.
Department of Energy, the Japanese Monbukagakusho, and the Max Planck
Society. The \textsc{sdss} Web site is \url{http://www.sdss.org/}.

The \textsc{sdss} is managed by the Astrophysical Research Consortium
(\textsc{arc}) for the Participating Institutions.  The Participating
Institutions are The University of Chicago, Fermilab, the Institute for
Advanced Study, the Japan Participation Group, The Johns Hopkins
University, the Korean Scientist Group, Los Alamos National Laboratory,
the Max-Planck-Institute for Astronomy (\textsc{mpia}), the
Max-Planck-Institute for Astrophysics (\textsc{mpa}), New Mexico State
University, University of Pittsburgh, University of Portsmouth,
Princeton University, the United States Naval Observatory, and the
University of Washington.



\section{Specific Software Acknowledgments}

\subsubsection{Minpack}
This product includes software developed by the University of Chicago, as Operator of
the Argonne National Laboratory.


\section{Miscellaneous Useful Software}

The development of \imfit{} has benefitted from the C++ unit-testing
framework CxxTest,\footnote{\url{https://cxxtest.com}} and also from the
static analyzers
Cppcheck\footnote{\url{http://cppcheck.sourceforge.net}} and the Clang
Static Analyzer.\footnote{\url{https://clang-analyzer.llvm.org}}



\bibliographystyle{plainnat}

\begin{thebibliography}{}


\bibitem[Abazajian et al.(2009)]{abazajian09} Abazajian, K. N.., et al.\ 2009, ``The Seventh 
Data Release of the Sloan Digital Sky Survey'', \textit{Astrophys.J. Supplement} \textbf{182}: 182.

\bibitem[Aguerri, M{\'e}ndez-Abreu, \& Corsini(2009)]{aguerri09}
Aguerri, J.~A.~L., M{\'e}ndez-Abreu, J., and Corsini, E.~M. 2009, ``The
population of barred galaxies in the local universe. I. Detection and
characterisation of bars'', \textit{Astron.\ Astrophys.} \textbf{495}:
491.

\bibitem[Athanassoula et al.(1990)]{athanassoula90} Athanassoula, E., Morin, S., Wozniak, H.,
Puy, D., Pierce, M. J., Lombard, J., and Bosma, A. 1990, \textit{Monthly Notices of the Royal
Astronomical Society} \textbf{245}: 130.

\bibitem[Ciotti \& Bertin(1999)]{ciotti99} Ciotti, L., and Bertin, G. 1999,
''Analytical properties of the R$^{1/m}$ law'', \textit{Astron.\ Astrophys.}
\textbf{352}: 447.

\bibitem[de Souza, Gadotti, \& dos Anjos(2004)]{desouza04} de Souza, R. E.,
Gadotti, D. A., and dos Anjos, S. 2004, ``BUDDA: A New Two-dimensional Bulge/Disk
Decomposition Code for Detailed Structural Analysis of Galaxies'',
\textit{Astrophys.J. Supplement} \textbf{153}: 411.

\bibitem[Elmegreen \& Elmegreen(1985)]{ee85} Elmegreen, D.~M., and
Elmegreen, B.~G. 1985, ``Properties of barred spiral galaxies'',
\textit{Astrophys.J.} \textbf{288}: 438.

\bibitem[Elson(1999)]{elson99} Elson, R.~A.~W. 1999, ``Stellar dynamics
in globular clusters'', in \textit{Globular clusters: X Canary Islands
Winter School of Astrophysics}, C. Mart{\'{\i}}nez Roger, I. Perez
Fourn{\'o}n, and F. S{\'a}nchez, eds., (Cambridge: Cambridge U. Press),
209.

\bibitem[Erwin, Pohlen, \& Beckman(2008)]{erwin08} Erwin, P.,
Pohlen, B., and Beckman, J. E. 2008, ``The Outer Disks of Early-Type Galaxies. I. 
Surface-Brightness Profiles of Barred Galaxies'', \textit{Astron.J.} \textbf{135}: 20.

\bibitem[Erwin(2015)]{erwin15} Erwin, P. 2015, ``Imfit: A Fast, Flexible
New Program for Astronomical Image Fitting'', \textit{Astrophys.J.} \textbf{799:} 226.

\bibitem[Erwin et al.(2020)]{erwin20} Erwin, P., et al. 2020,
``Composite Bulges  II. Classical Bulges and Nuclear Disks in Barred
Galaxies: The Contrasting Cases of NGC 4608 and NGC 4643'',
\textit{Monthly Notices of the Royal Astronomical Society}, submitted.

\bibitem[Ferrers(1877)]{ferrers} Ferrers, N. M. 1877, ``On the
Potentials of Ellipsoids, Ellipsoidal Shells, Elliptic Laminae, and
Elliptic Rings, of Variable Densities'', \textit{Quarterly Journal
of Pure and Applied Mathematics} \textbf{14}: 1.

\bibitem[Foreman-Mackey(2016)]{corner} Foreman-Mackey, D. 2016,
``corner.py: Scatterplot matrices in Python', \textit{The Journal of Open Source Software}
\textbf{1:} 24.

\bibitem[Gadotti(2008)]{gadotti08} Gadotti, D. A. 2008, ``Image
decomposition of barred galaxies and AGN hosts'', \textit{Monthly
Notices of the Royal Astronomical Society} \textbf{384}: 420.

\bibitem[Gelman \& Rubin(1992)]{gelman-rubin} Gelman, A., and Rubin,
D.~B. 1992, ``Inference from iterative simulation using multiple
sequences'', \textit{Statistical Science} \textbf{7}: 457.

\bibitem[Graham et al.(2003)]{graham03} Graham, A., Erwin, P., Trujillo, I., and
Asensio Ramos, A. 2003, ``A New Empirical Model for the Structural Analysis of
Early-Type Galaxies, and A Critical Review of the Nuker Model'',
\textit{Astron.J.} \textbf{125}: 2951.

\bibitem[Humphrey, Liu, \& Buote(2009)]{humphrey09} Humphrey, P.~J.,
Liu, W., and Buote, D.~A. 2009, ``{$\chi$}$^{2}$ and Poissonian Data:
Biases Even in the High-Count Regime and How to Avoid Them'',
\textit{Astrophys.J.} \textbf{693}: 822.

\bibitem[King(1962)]{king62} King, I. 1962, ``The structure of star
clusters. I. an empirical density law'', \textit{Astron.J.} \textbf{67}:
471.

\bibitem[Krist(1995)]{krist95} Krist, J. 1995, ``Simulation of HST PSFs using
Tiny Tim'', in \textit{Astronomical Data Analysis Software and Systems IV}, R.A.
Shaw, H.E. Payne, and J.J.E. Hayes, eds., \textit{ASP Conference Series}
\textbf{77}: 349.

\bibitem[Laurikainen, Salo, \& Buta(2005)]{laurikainen05} Laurikainen,
E., Salo, H., and Buta, R. 2005, ``Multicomponent decompositions for a
sample of S0 galaxies'', \textit{Monthly Notices of the Royal
Astronomical Society} \textbf{362}: 1319.

\bibitem[MacArthur, Courteau, \& Holtzman(2003)]{macarthur03} MacArthur, L. A.,
Courteau, S., and Holtzman, J. A. 2003, ``Structure of Disk-dominated Galaxies.
I. Bulge/Disk Parameters, Simulations, and Secular Evolution'',
\textit{Astrophys.J.} \textbf{582}: 689.

\bibitem[Moffat(1969)]{moffat69} Moffat, A.~F.~J. 1969, ``A Theoretical
Investigation of Focal Stellar Images in the Photographic Emulsion and
Application to Photographic Photometry'', \textit{Astron.\ Astrophys.} \textbf{3}: 455.

\bibitem[Mor{\'e}(1978)]{more78} Mor{\'e}, J.~J. 1978, ``The
Levenberg-Marquardt algorithm: Implementation and theory'', in
\textit{Numerical Analysis}, G.A. Watson, ed., \textit{Lecture Notes in
Mathematics} \textbf{630}: 105.

\bibitem[Peng et al.(2002)]{peng02} Peng, C. Y., Ho, L. C., Impey, C. D., and
Rix, H. W. 2002, ``Detailed Structural Decomposition of Galaxy Images'',
\textit{Astron.J.} \textbf{124}: 266.

\bibitem[Peng et al.(2010)]{peng10} Peng, C. Y., Ho, L. C., Impey, C. D., and
Rix, H. W. 2010, ``Detailed Decomposition of Galaxy Images. II. Beyond
Axisymmetric Models'', \textit{Astron.J.} \textbf{139}: 2097.

\bibitem[S{\'e}rsic(1968)]{sersic68} S{\'e}rsic, J.-L. 1968, \textit{Atlas de 
Galaxias Australes} (Cordoba: Obs.\ Astron.).

\bibitem[Storn \& Price(1997)]{de} Storn, R., and Price, K. 1997, ``Differential
Evolution -- A Simple and Efficient Heuristic for Global Optimization Over
Continuous Spaces'', \textit{Journal of Global Optimization} \textbf{11}: 314.

\bibitem[ter Braak(2006)]{ter-braak06} ter Braak, C.J.F. 2006.
``A Markov chain Monte Carlo version of the genetic
algorithm differential evolution: easy Bayesian computing for real
parameter spaces'', \textit{Statistics and Computing} \textbf{16} (4): 239--249.

\bibitem[ter Braak \& Vrugt(2008)]{ter-braak08} ter Braak, C., and J.
Vrugt 2008. ``Differential Evolution Markov Chain with snooker updater
and fewer chains'', \textit{Statistics and Computing} \textbf{18} (4): 435--446.

\bibitem[Trujillo et al.(2001)]{trujillo01} Trujillo, I., Aguerri, J. A. L.,
Cepa, J., and Guti{\'e}rrez, C. M. 2001, ``The effects of seeing on S{\'e}rsic
profiles -- II. The Moffat PSF'', \textit{Monthly Notices of the Royal
Astronomical Society} \textbf{328}: 977.

\bibitem[Trujillo et al.(2004)]{trujillo04} Trujillo, I., Erwin, P., Asensio
Ramos, A., and Graham, A. 2004, ``Evidence for a New Elliptical-Galaxy Paradigm:
S{\'e}rsic and Core Galaxies'', \textit{Astron.J.} \textbf{127}: 1917.

\bibitem[van der Kruit \& Searle(1981)]{vdk81} van der Kruit, P. C., and
Searle, L. 1981, ``Surface Photometry of Edge-on Spiral Galaxies: I. A
Model for the Three-dimensional Distribution of Light in Galactic
Disks'', \textit{Astron.\ Astrophys.} \textbf{95}: 105.

\bibitem[van der Kruit(1988)]{vdk88} van der Kruit, P. 1988, ``The
Three-dimensional Distribution of Light and Mass in Disks of Spiral
Galaxies'', \textit{Astron.\ Astrophys.} \textbf{192}: 117.

\bibitem[Vrugt et al.(2009)]{vrugt09} Vrugt, J. A., ter Braak, C. J. F.,
Diks, C. G. H., Robinson, B. A., Hyman, J. M., and Higdon, D. 2009.
``Accelerating Markov chain Monte Carlo simulation by differential
evolution with self-adaptive randomized subspace sampling'',
\textit{International Journal of Nonlinear Sciences and Numerical
Simulation} \textbf{10} (3): 273--290.

\bibitem[Vrugt(2016)]{vrugt16} Vrugt, J. A. 2016. ``Markov chain Monte
Carlo simulation using the DREAM software package: Theory, concepts, and
MATLAB implementation'', \textit{Environmental Modelling and Software}
\textbf{75}: 273--316.

\bibitem[Yoachim \& Dalcanton(2006)]{yoachim06} Yoachim, P., and Dalconton, J. J.
2006, ``Structural Parameters of Thin and Thick Disks in Edge-On Disk
Galaxies'', \textit{Astron.J.} \textbf{131}: 226.

\bibitem[York et al.(2000)]{york00} York, D. G., et al.\ 2000, ``The Sloan Digital 
Sky Survey: Technical Summary'', \textit{Astron.J.} \textbf{120}: 1579.


\end{thebibliography}
%\bibliography{imfit_howto}




\end{document}
